{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "import os\n",
    "import pathlib\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers import models, util, datasets, evaluation, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import BertConfig, BertForPreTraining, BertTokenizer,BertModel\n",
    "import random\n",
    "import logging\n",
    "import pathlib, os\n",
    "import nltk\n",
    "from beir import util, LoggingHandler\n",
    "\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cgrdj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /Users/cgrdj/Documents/Code/sentence-transformers/datasets/scifact\n"
     ]
    }
   ],
   "source": [
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:29:12 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 9696.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:29:12 - Loaded 5183 TRAIN Documents.\n",
      "2024-03-16 00:29:12 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2024-03-16 00:29:12 - Loading Queries...\n",
      "2024-03-16 00:29:12 - Loaded 809 TRAIN Queries.\n",
      "2024-03-16 00:29:12 - Query Example: 0-dimensional biomaterials lack inductive properties.\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"train\") # or split = \"train\" or \"dev\"\n",
    "unsupervised_train_data =  list(queries.values())#+[data['title']+' \\n '+data['text'] for data in list(corpus.values())]\n",
    "random.Random(0).shuffle(unsupervised_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:29:14 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5183 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 20530.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:29:14 - Loaded 5183 TEST Documents.\n",
      "2024-03-16 00:29:14 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2024-03-16 00:29:14 - Loading Queries...\n",
      "2024-03-16 00:29:14 - Loaded 300 TEST Queries.\n",
      "2024-03-16 00:29:14 - Query Example: 0-dimensional biomaterials show inductive properties.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"datasets/scifact\"\n",
    "test_corpus, test_queries, test_qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m word_embedding_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTransformer(model_name)\n\u001b[1;32m      4\u001b[0m pooling_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPooling(word_embedding_model\u001b[38;5;241m.\u001b[39mget_word_embedding_dimension(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mword_embedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/sentence_transformers/SentenceTransformer.py:214\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[1;32m    211\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    212\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault prompt name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in the configured prompts \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdictionary with keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your sentence transformer model using CLS pooling\n",
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model],device='cuda')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSDAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:41:55 - When tie_encoder_decoder=True, the decoder_name_or_path will be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "# Define a list with sentences (1k - 100k sentences)\n",
    "train_sentences = unsupervised_train_data\n",
    "\n",
    "# Create the special \n",
    "# denoising dataset that adds noise on-the-fly\n",
    "train_dataset = datasets.DenoisingAutoEncoderDataset(train_sentences)\n",
    "\n",
    "# DataLoader to batch your data\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    model, decoder_name_or_path=model_name, tie_encoder_decoder=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import losses, util, models\n",
    "from sentence_transformers.evaluation import SentenceEvaluator\n",
    "\n",
    "class SaveCallback(SentenceEvaluator):\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def __call__(self, model, epoch, steps,output_path=None,):\n",
    "        model.save(f\"{self.save_path}/epoch-{epoch}-steps-{steps}\")\n",
    "        return 0\n",
    "\n",
    "# Initialize the callback\n",
    "save_callback = SaveCallback(save_path=\"output/tsdae-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "                                                          \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.88it/s]\n",
      "Epoch:   0%|          | 0/20 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:42:57 - Save model to output/tsdae-model/epoch-0-steps-51\n",
      "2024-03-10 14:42:58 - Save model to output/tsdae-model_queries\n",
      "2024-03-10 14:42:58 - Save model to output/tsdae-model/epoch-0-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:28<00:00,  1.77it/s]\n",
      "Epoch:   5%|▌         | 1/20 [00:56<08:36, 27.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:43:26 - Save model to output/tsdae-model/epoch-1-steps-51\n",
      "2024-03-10 14:43:27 - Save model to output/tsdae-model/epoch-1-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:32<00:00,  1.56it/s]\n",
      "Epoch:  10%|█         | 2/20 [01:28<08:27, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:43:59 - Save model to output/tsdae-model/epoch-2-steps-51\n",
      "2024-03-10 14:43:59 - Save model to output/tsdae-model/epoch-2-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.87it/s]\n",
      "Epoch:  20%|██        | 4/20 [01:56<07:46, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:44:27 - Save model to output/tsdae-model/epoch-3-steps-51\n",
      "2024-03-10 14:44:27 - Save model to output/tsdae-model/epoch-3-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.83it/s]\n",
      "Epoch:  25%|██▌       | 5/20 [02:24<07:10, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:44:55 - Save model to output/tsdae-model/epoch-4-steps-51\n",
      "2024-03-10 14:44:55 - Save model to output/tsdae-model/epoch-4-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.90it/s]\n",
      "Epoch:  30%|███       | 6/20 [02:51<06:33, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:45:21 - Save model to output/tsdae-model/epoch-5-steps-51\n",
      "2024-03-10 14:45:22 - Save model to output/tsdae-model/epoch-5-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.93it/s]\n",
      "Epoch:  35%|███▌      | 7/20 [03:17<05:58, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:45:48 - Save model to output/tsdae-model/epoch-6-steps-51\n",
      "2024-03-10 14:45:48 - Save model to output/tsdae-model/epoch-6-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.89it/s]\n",
      "Epoch:  40%|████      | 8/20 [03:44<05:29, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:46:15 - Save model to output/tsdae-model/epoch-7-steps-51\n",
      "2024-03-10 14:46:15 - Save model to output/tsdae-model/epoch-7-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.88it/s]\n",
      "Epoch:  45%|████▌     | 9/20 [04:11<05:01, 27.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:46:42 - Save model to output/tsdae-model/epoch-8-steps-51\n",
      "2024-03-10 14:46:42 - Save model to output/tsdae-model/epoch-8-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.90it/s]\n",
      "Epoch:  50%|█████     | 10/20 [04:38<04:32, 27.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:47:09 - Save model to output/tsdae-model/epoch-9-steps-51\n",
      "2024-03-10 14:47:09 - Save model to output/tsdae-model/epoch-9-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.89it/s]\n",
      "Epoch:  55%|█████▌    | 11/20 [05:06<04:04, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:47:36 - Save model to output/tsdae-model/epoch-10-steps-51\n",
      "2024-03-10 14:47:37 - Save model to output/tsdae-model/epoch-10-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.89it/s]\n",
      "Epoch:  60%|██████    | 12/20 [05:33<03:37, 27.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:48:03 - Save model to output/tsdae-model/epoch-11-steps-51\n",
      "2024-03-10 14:48:04 - Save model to output/tsdae-model/epoch-11-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.90it/s]\n",
      "Epoch:  65%|██████▌   | 13/20 [06:00<03:09, 27.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:48:30 - Save model to output/tsdae-model/epoch-12-steps-51\n",
      "2024-03-10 14:48:30 - Save model to output/tsdae-model/epoch-12-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.91it/s]\n",
      "Epoch:  70%|███████   | 14/20 [06:26<02:41, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:48:57 - Save model to output/tsdae-model/epoch-13-steps-51\n",
      "2024-03-10 14:48:57 - Save model to output/tsdae-model/epoch-13-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.92it/s]\n",
      "Epoch:  75%|███████▌  | 15/20 [06:53<02:14, 26.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:49:24 - Save model to output/tsdae-model/epoch-14-steps-51\n",
      "2024-03-10 14:49:24 - Save model to output/tsdae-model/epoch-14-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.87it/s]\n",
      "Epoch:  80%|████████  | 16/20 [07:20<01:48, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:49:51 - Save model to output/tsdae-model/epoch-15-steps-51\n",
      "2024-03-10 14:49:51 - Save model to output/tsdae-model/epoch-15-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.90it/s]\n",
      "Epoch:  85%|████████▌ | 17/20 [07:47<01:21, 27.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:50:18 - Save model to output/tsdae-model/epoch-16-steps-51\n",
      "2024-03-10 14:50:18 - Save model to output/tsdae-model/epoch-16-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.86it/s]\n",
      "Epoch:  90%|█████████ | 18/20 [08:15<00:54, 27.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:50:46 - Save model to output/tsdae-model/epoch-17-steps-51\n",
      "2024-03-10 14:50:46 - Save model to output/tsdae-model/epoch-17-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:26<00:00,  1.92it/s]\n",
      "Epoch:  95%|█████████▌| 19/20 [08:41<00:27, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:51:12 - Save model to output/tsdae-model/epoch-18-steps-51\n",
      "2024-03-10 14:51:12 - Save model to output/tsdae-model/epoch-18-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Iteration: 100%|██████████| 51/51 [00:27<00:00,  1.89it/s]\n",
      "Epoch: 100%|██████████| 20/20 [09:09<00:00, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:51:39 - Save model to output/tsdae-model/epoch-19-steps-51\n",
      "2024-03-10 14:51:40 - Save model to output/tsdae-model/epoch-19-steps--1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(train_dataloader) * 1  # for one epoch, adjust as needed\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    scheduler=\"constantlr\",\n",
    "    optimizer_params={\"lr\": 9e-5},\n",
    "    show_progress_bar=True,\n",
    "    evaluator=save_callback,  # Add your save callback here\n",
    "    evaluation_steps=total_steps,  # Set this to a high number to avoid frequent evaluations, or adjust as necessary\n",
    "    output_path=\"output/tsdae-model_queries\"  # This ensures the final model is saved at the specified location.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-09 18:46:41 - Load pretrained SentenceTransformer: output/tsdae-model\n",
      "2024-03-09 18:46:41 - Use pytorch device_name: mps\n"
     ]
    }
   ],
   "source": [
    "loaded_model = SentenceTransformer(\"output/tsdae-model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEIR retrival framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:55:36 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-19-steps-51\n",
      "2024-03-10 14:55:36 - Use pytorch device_name: mps\n",
      "2024-03-10 14:55:37 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:55:39 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:55:39 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:55:39 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:55:39 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:42<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:56:23 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:56:24 - \n",
      "\n",
      "2024-03-10 14:56:24 - NDCG@1: 0.0067\n",
      "2024-03-10 14:56:24 - NDCG@3: 0.0067\n",
      "2024-03-10 14:56:24 - NDCG@5: 0.0067\n",
      "2024-03-10 14:56:24 - NDCG@10: 0.0078\n",
      "2024-03-10 14:56:24 - NDCG@100: 0.0140\n",
      "2024-03-10 14:56:24 - NDCG@1000: 0.0582\n",
      "2024-03-10 14:56:24 - \n",
      "\n",
      "2024-03-10 14:56:24 - MAP@1: 0.0067\n",
      "2024-03-10 14:56:24 - MAP@3: 0.0067\n",
      "2024-03-10 14:56:24 - MAP@5: 0.0067\n",
      "2024-03-10 14:56:24 - MAP@10: 0.0071\n",
      "2024-03-10 14:56:24 - MAP@100: 0.0079\n",
      "2024-03-10 14:56:24 - MAP@1000: 0.0089\n",
      "2024-03-10 14:56:24 - \n",
      "\n",
      "2024-03-10 14:56:24 - Recall@1: 0.0067\n",
      "2024-03-10 14:56:24 - Recall@3: 0.0067\n",
      "2024-03-10 14:56:24 - Recall@5: 0.0067\n",
      "2024-03-10 14:56:24 - Recall@10: 0.0100\n",
      "2024-03-10 14:56:24 - Recall@100: 0.0450\n",
      "2024-03-10 14:56:24 - Recall@1000: 0.4221\n",
      "2024-03-10 14:56:24 - \n",
      "\n",
      "2024-03-10 14:56:24 - P@1: 0.0067\n",
      "2024-03-10 14:56:24 - P@3: 0.0022\n",
      "2024-03-10 14:56:24 - P@5: 0.0013\n",
      "2024-03-10 14:56:24 - P@10: 0.0010\n",
      "2024-03-10 14:56:24 - P@100: 0.0005\n",
      "2024-03-10 14:56:24 - P@1000: 0.0005\n",
      "2024-03-10 14:56:24 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-18-steps-51\n",
      "2024-03-10 14:56:24 - Use pytorch device_name: mps\n",
      "2024-03-10 14:56:24 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 29.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:56:25 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:56:25 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:56:25 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:56:25 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:33<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:57:00 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:57:00 - \n",
      "\n",
      "2024-03-10 14:57:00 - NDCG@1: 0.0067\n",
      "2024-03-10 14:57:00 - NDCG@3: 0.0083\n",
      "2024-03-10 14:57:00 - NDCG@5: 0.0083\n",
      "2024-03-10 14:57:00 - NDCG@10: 0.0083\n",
      "2024-03-10 14:57:00 - NDCG@100: 0.0126\n",
      "2024-03-10 14:57:00 - NDCG@1000: 0.0624\n",
      "2024-03-10 14:57:00 - \n",
      "\n",
      "2024-03-10 14:57:00 - MAP@1: 0.0067\n",
      "2024-03-10 14:57:00 - MAP@3: 0.0078\n",
      "2024-03-10 14:57:00 - MAP@5: 0.0078\n",
      "2024-03-10 14:57:00 - MAP@10: 0.0078\n",
      "2024-03-10 14:57:00 - MAP@100: 0.0083\n",
      "2024-03-10 14:57:00 - MAP@1000: 0.0096\n",
      "2024-03-10 14:57:00 - \n",
      "\n",
      "2024-03-10 14:57:00 - Recall@1: 0.0067\n",
      "2024-03-10 14:57:00 - Recall@3: 0.0100\n",
      "2024-03-10 14:57:00 - Recall@5: 0.0100\n",
      "2024-03-10 14:57:00 - Recall@10: 0.0100\n",
      "2024-03-10 14:57:00 - Recall@100: 0.0328\n",
      "2024-03-10 14:57:00 - Recall@1000: 0.4503\n",
      "2024-03-10 14:57:00 - \n",
      "\n",
      "2024-03-10 14:57:00 - P@1: 0.0067\n",
      "2024-03-10 14:57:00 - P@3: 0.0033\n",
      "2024-03-10 14:57:00 - P@5: 0.0020\n",
      "2024-03-10 14:57:00 - P@10: 0.0010\n",
      "2024-03-10 14:57:00 - P@100: 0.0004\n",
      "2024-03-10 14:57:00 - P@1000: 0.0005\n",
      "2024-03-10 14:57:00 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-2-steps-375\n",
      "2024-03-10 14:57:01 - Use pytorch device_name: mps\n",
      "2024-03-10 14:57:01 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:57:02 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:57:02 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:57:02 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:57:02 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:35<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:57:39 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:57:39 - \n",
      "\n",
      "2024-03-10 14:57:39 - NDCG@1: 0.0033\n",
      "2024-03-10 14:57:39 - NDCG@3: 0.0033\n",
      "2024-03-10 14:57:39 - NDCG@5: 0.0046\n",
      "2024-03-10 14:57:39 - NDCG@10: 0.0067\n",
      "2024-03-10 14:57:39 - NDCG@100: 0.0265\n",
      "2024-03-10 14:57:39 - NDCG@1000: 0.0904\n",
      "2024-03-10 14:57:39 - \n",
      "\n",
      "2024-03-10 14:57:39 - MAP@1: 0.0033\n",
      "2024-03-10 14:57:39 - MAP@3: 0.0033\n",
      "2024-03-10 14:57:39 - MAP@5: 0.0040\n",
      "2024-03-10 14:57:39 - MAP@10: 0.0048\n",
      "2024-03-10 14:57:39 - MAP@100: 0.0073\n",
      "2024-03-10 14:57:39 - MAP@1000: 0.0090\n",
      "2024-03-10 14:57:39 - \n",
      "\n",
      "2024-03-10 14:57:39 - Recall@1: 0.0033\n",
      "2024-03-10 14:57:39 - Recall@3: 0.0033\n",
      "2024-03-10 14:57:39 - Recall@5: 0.0067\n",
      "2024-03-10 14:57:39 - Recall@10: 0.0133\n",
      "2024-03-10 14:57:39 - Recall@100: 0.1201\n",
      "2024-03-10 14:57:39 - Recall@1000: 0.6493\n",
      "2024-03-10 14:57:39 - \n",
      "\n",
      "2024-03-10 14:57:39 - P@1: 0.0033\n",
      "2024-03-10 14:57:39 - P@3: 0.0011\n",
      "2024-03-10 14:57:39 - P@5: 0.0013\n",
      "2024-03-10 14:57:39 - P@10: 0.0013\n",
      "2024-03-10 14:57:39 - P@100: 0.0013\n",
      "2024-03-10 14:57:39 - P@1000: 0.0007\n",
      "2024-03-10 14:57:39 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-13-steps-51\n",
      "2024-03-10 14:57:39 - Use pytorch device_name: mps\n",
      "2024-03-10 14:57:39 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:57:41 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:57:41 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:57:41 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:57:41 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:36<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:58:19 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:58:19 - \n",
      "\n",
      "2024-03-10 14:58:19 - NDCG@1: 0.0067\n",
      "2024-03-10 14:58:19 - NDCG@3: 0.0067\n",
      "2024-03-10 14:58:19 - NDCG@5: 0.0081\n",
      "2024-03-10 14:58:19 - NDCG@10: 0.0081\n",
      "2024-03-10 14:58:19 - NDCG@100: 0.0149\n",
      "2024-03-10 14:58:19 - NDCG@1000: 0.0635\n",
      "2024-03-10 14:58:19 - \n",
      "\n",
      "2024-03-10 14:58:19 - MAP@1: 0.0067\n",
      "2024-03-10 14:58:19 - MAP@3: 0.0067\n",
      "2024-03-10 14:58:19 - MAP@5: 0.0075\n",
      "2024-03-10 14:58:19 - MAP@10: 0.0075\n",
      "2024-03-10 14:58:19 - MAP@100: 0.0086\n",
      "2024-03-10 14:58:19 - MAP@1000: 0.0098\n",
      "2024-03-10 14:58:19 - \n",
      "\n",
      "2024-03-10 14:58:19 - Recall@1: 0.0067\n",
      "2024-03-10 14:58:19 - Recall@3: 0.0067\n",
      "2024-03-10 14:58:19 - Recall@5: 0.0100\n",
      "2024-03-10 14:58:19 - Recall@10: 0.0100\n",
      "2024-03-10 14:58:19 - Recall@100: 0.0450\n",
      "2024-03-10 14:58:19 - Recall@1000: 0.4536\n",
      "2024-03-10 14:58:19 - \n",
      "\n",
      "2024-03-10 14:58:19 - P@1: 0.0067\n",
      "2024-03-10 14:58:19 - P@3: 0.0022\n",
      "2024-03-10 14:58:19 - P@5: 0.0020\n",
      "2024-03-10 14:58:19 - P@10: 0.0010\n",
      "2024-03-10 14:58:19 - P@100: 0.0005\n",
      "2024-03-10 14:58:19 - P@1000: 0.0005\n",
      "2024-03-10 14:58:19 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-12-steps-51\n",
      "2024-03-10 14:58:19 - Use pytorch device_name: mps\n",
      "2024-03-10 14:58:19 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:58:21 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:58:21 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:58:21 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:58:21 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:41<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:59:04 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:59:04 - \n",
      "\n",
      "2024-03-10 14:59:04 - NDCG@1: 0.0067\n",
      "2024-03-10 14:59:04 - NDCG@3: 0.0067\n",
      "2024-03-10 14:59:04 - NDCG@5: 0.0081\n",
      "2024-03-10 14:59:04 - NDCG@10: 0.0081\n",
      "2024-03-10 14:59:04 - NDCG@100: 0.0123\n",
      "2024-03-10 14:59:04 - NDCG@1000: 0.0554\n",
      "2024-03-10 14:59:04 - \n",
      "\n",
      "2024-03-10 14:59:04 - MAP@1: 0.0067\n",
      "2024-03-10 14:59:04 - MAP@3: 0.0067\n",
      "2024-03-10 14:59:04 - MAP@5: 0.0075\n",
      "2024-03-10 14:59:04 - MAP@10: 0.0075\n",
      "2024-03-10 14:59:04 - MAP@100: 0.0081\n",
      "2024-03-10 14:59:04 - MAP@1000: 0.0092\n",
      "2024-03-10 14:59:04 - \n",
      "\n",
      "2024-03-10 14:59:04 - Recall@1: 0.0067\n",
      "2024-03-10 14:59:04 - Recall@3: 0.0067\n",
      "2024-03-10 14:59:04 - Recall@5: 0.0100\n",
      "2024-03-10 14:59:04 - Recall@10: 0.0100\n",
      "2024-03-10 14:59:04 - Recall@100: 0.0317\n",
      "2024-03-10 14:59:04 - Recall@1000: 0.3928\n",
      "2024-03-10 14:59:04 - \n",
      "\n",
      "2024-03-10 14:59:04 - P@1: 0.0067\n",
      "2024-03-10 14:59:04 - P@3: 0.0022\n",
      "2024-03-10 14:59:04 - P@5: 0.0020\n",
      "2024-03-10 14:59:04 - P@10: 0.0010\n",
      "2024-03-10 14:59:04 - P@100: 0.0003\n",
      "2024-03-10 14:59:04 - P@1000: 0.0004\n",
      "2024-03-10 14:59:04 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-3-steps-51\n",
      "2024-03-10 14:59:04 - Use pytorch device_name: mps\n",
      "2024-03-10 14:59:04 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 21.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:59:06 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:59:06 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:59:06 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:59:06 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:42<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:59:50 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 14:59:50 - \n",
      "\n",
      "2024-03-10 14:59:50 - NDCG@1: 0.0067\n",
      "2024-03-10 14:59:50 - NDCG@3: 0.0067\n",
      "2024-03-10 14:59:50 - NDCG@5: 0.0067\n",
      "2024-03-10 14:59:50 - NDCG@10: 0.0067\n",
      "2024-03-10 14:59:50 - NDCG@100: 0.0097\n",
      "2024-03-10 14:59:50 - NDCG@1000: 0.0474\n",
      "2024-03-10 14:59:50 - \n",
      "\n",
      "2024-03-10 14:59:50 - MAP@1: 0.0067\n",
      "2024-03-10 14:59:50 - MAP@3: 0.0067\n",
      "2024-03-10 14:59:50 - MAP@5: 0.0067\n",
      "2024-03-10 14:59:50 - MAP@10: 0.0067\n",
      "2024-03-10 14:59:50 - MAP@100: 0.0069\n",
      "2024-03-10 14:59:50 - MAP@1000: 0.0076\n",
      "2024-03-10 14:59:50 - \n",
      "\n",
      "2024-03-10 14:59:50 - Recall@1: 0.0067\n",
      "2024-03-10 14:59:50 - Recall@3: 0.0067\n",
      "2024-03-10 14:59:50 - Recall@5: 0.0067\n",
      "2024-03-10 14:59:50 - Recall@10: 0.0067\n",
      "2024-03-10 14:59:50 - Recall@100: 0.0250\n",
      "2024-03-10 14:59:50 - Recall@1000: 0.3547\n",
      "2024-03-10 14:59:50 - \n",
      "\n",
      "2024-03-10 14:59:50 - P@1: 0.0067\n",
      "2024-03-10 14:59:50 - P@3: 0.0022\n",
      "2024-03-10 14:59:50 - P@5: 0.0013\n",
      "2024-03-10 14:59:50 - P@10: 0.0007\n",
      "2024-03-10 14:59:50 - P@100: 0.0003\n",
      "2024-03-10 14:59:50 - P@1000: 0.0004\n",
      "2024-03-10 14:59:50 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-2-steps-51\n",
      "2024-03-10 14:59:50 - Use pytorch device_name: mps\n",
      "2024-03-10 14:59:50 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 14:59:52 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 14:59:52 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 14:59:52 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 14:59:52 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:46<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:00:41 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:00:41 - \n",
      "\n",
      "2024-03-10 15:00:41 - NDCG@1: 0.0000\n",
      "2024-03-10 15:00:41 - NDCG@3: 0.0000\n",
      "2024-03-10 15:00:41 - NDCG@5: 0.0000\n",
      "2024-03-10 15:00:41 - NDCG@10: 0.0010\n",
      "2024-03-10 15:00:41 - NDCG@100: 0.0039\n",
      "2024-03-10 15:00:41 - NDCG@1000: 0.0388\n",
      "2024-03-10 15:00:41 - \n",
      "\n",
      "2024-03-10 15:00:41 - MAP@1: 0.0000\n",
      "2024-03-10 15:00:41 - MAP@3: 0.0000\n",
      "2024-03-10 15:00:41 - MAP@5: 0.0000\n",
      "2024-03-10 15:00:41 - MAP@10: 0.0004\n",
      "2024-03-10 15:00:41 - MAP@100: 0.0008\n",
      "2024-03-10 15:00:41 - MAP@1000: 0.0015\n",
      "2024-03-10 15:00:41 - \n",
      "\n",
      "2024-03-10 15:00:41 - Recall@1: 0.0000\n",
      "2024-03-10 15:00:41 - Recall@3: 0.0000\n",
      "2024-03-10 15:00:41 - Recall@5: 0.0000\n",
      "2024-03-10 15:00:41 - Recall@10: 0.0033\n",
      "2024-03-10 15:00:41 - Recall@100: 0.0183\n",
      "2024-03-10 15:00:41 - Recall@1000: 0.3228\n",
      "2024-03-10 15:00:41 - \n",
      "\n",
      "2024-03-10 15:00:41 - P@1: 0.0000\n",
      "2024-03-10 15:00:41 - P@3: 0.0000\n",
      "2024-03-10 15:00:41 - P@5: 0.0000\n",
      "2024-03-10 15:00:41 - P@10: 0.0003\n",
      "2024-03-10 15:00:41 - P@100: 0.0002\n",
      "2024-03-10 15:00:41 - P@1000: 0.0004\n",
      "2024-03-10 15:00:41 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-9-steps-375\n",
      "2024-03-10 15:00:41 - Use pytorch device_name: mps\n",
      "2024-03-10 15:00:41 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:00:43 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:00:43 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:00:43 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:00:43 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:44<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:01:30 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:01:30 - \n",
      "\n",
      "2024-03-10 15:01:30 - NDCG@1: 0.0167\n",
      "2024-03-10 15:01:30 - NDCG@3: 0.0242\n",
      "2024-03-10 15:01:30 - NDCG@5: 0.0352\n",
      "2024-03-10 15:01:30 - NDCG@10: 0.0523\n",
      "2024-03-10 15:01:30 - NDCG@100: 0.1032\n",
      "2024-03-10 15:01:30 - NDCG@1000: 0.1688\n",
      "2024-03-10 15:01:30 - \n",
      "\n",
      "2024-03-10 15:01:30 - MAP@1: 0.0167\n",
      "2024-03-10 15:01:30 - MAP@3: 0.0222\n",
      "2024-03-10 15:01:30 - MAP@5: 0.0281\n",
      "2024-03-10 15:01:30 - MAP@10: 0.0351\n",
      "2024-03-10 15:01:30 - MAP@100: 0.0431\n",
      "2024-03-10 15:01:30 - MAP@1000: 0.0455\n",
      "2024-03-10 15:01:30 - \n",
      "\n",
      "2024-03-10 15:01:30 - Recall@1: 0.0167\n",
      "2024-03-10 15:01:30 - Recall@3: 0.0300\n",
      "2024-03-10 15:01:30 - Recall@5: 0.0558\n",
      "2024-03-10 15:01:30 - Recall@10: 0.1071\n",
      "2024-03-10 15:01:30 - Recall@100: 0.3661\n",
      "2024-03-10 15:01:30 - Recall@1000: 0.8857\n",
      "2024-03-10 15:01:30 - \n",
      "\n",
      "2024-03-10 15:01:30 - P@1: 0.0167\n",
      "2024-03-10 15:01:30 - P@3: 0.0100\n",
      "2024-03-10 15:01:30 - P@5: 0.0120\n",
      "2024-03-10 15:01:30 - P@10: 0.0120\n",
      "2024-03-10 15:01:30 - P@100: 0.0042\n",
      "2024-03-10 15:01:30 - P@1000: 0.0010\n",
      "2024-03-10 15:01:30 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-9-steps-51\n",
      "2024-03-10 15:01:30 - Use pytorch device_name: mps\n",
      "2024-03-10 15:01:30 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:01<00:00, 19.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:01:32 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:01:32 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:01:32 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:01:32 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:45<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:02:19 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:02:19 - \n",
      "\n",
      "2024-03-10 15:02:19 - NDCG@1: 0.0067\n",
      "2024-03-10 15:02:19 - NDCG@3: 0.0088\n",
      "2024-03-10 15:02:19 - NDCG@5: 0.0088\n",
      "2024-03-10 15:02:19 - NDCG@10: 0.0088\n",
      "2024-03-10 15:02:19 - NDCG@100: 0.0114\n",
      "2024-03-10 15:02:19 - NDCG@1000: 0.0592\n",
      "2024-03-10 15:02:19 - \n",
      "\n",
      "2024-03-10 15:02:19 - MAP@1: 0.0067\n",
      "2024-03-10 15:02:19 - MAP@3: 0.0083\n",
      "2024-03-10 15:02:19 - MAP@5: 0.0083\n",
      "2024-03-10 15:02:19 - MAP@10: 0.0083\n",
      "2024-03-10 15:02:19 - MAP@100: 0.0087\n",
      "2024-03-10 15:02:19 - MAP@1000: 0.0098\n",
      "2024-03-10 15:02:19 - \n",
      "\n",
      "2024-03-10 15:02:19 - Recall@1: 0.0067\n",
      "2024-03-10 15:02:19 - Recall@3: 0.0100\n",
      "2024-03-10 15:02:19 - Recall@5: 0.0100\n",
      "2024-03-10 15:02:19 - Recall@10: 0.0100\n",
      "2024-03-10 15:02:19 - Recall@100: 0.0233\n",
      "2024-03-10 15:02:19 - Recall@1000: 0.4276\n",
      "2024-03-10 15:02:19 - \n",
      "\n",
      "2024-03-10 15:02:19 - P@1: 0.0067\n",
      "2024-03-10 15:02:19 - P@3: 0.0033\n",
      "2024-03-10 15:02:19 - P@5: 0.0020\n",
      "2024-03-10 15:02:19 - P@10: 0.0010\n",
      "2024-03-10 15:02:19 - P@100: 0.0003\n",
      "2024-03-10 15:02:19 - P@1000: 0.0005\n",
      "2024-03-10 15:02:19 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-8-steps-51\n",
      "2024-03-10 15:02:19 - Use pytorch device_name: mps\n",
      "2024-03-10 15:02:19 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:02:21 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:02:21 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:02:21 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:02:21 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:47<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:03:11 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:03:11 - \n",
      "\n",
      "2024-03-10 15:03:11 - NDCG@1: 0.0033\n",
      "2024-03-10 15:03:11 - NDCG@3: 0.0050\n",
      "2024-03-10 15:03:11 - NDCG@5: 0.0064\n",
      "2024-03-10 15:03:11 - NDCG@10: 0.0074\n",
      "2024-03-10 15:03:11 - NDCG@100: 0.0096\n",
      "2024-03-10 15:03:11 - NDCG@1000: 0.0595\n",
      "2024-03-10 15:03:11 - \n",
      "\n",
      "2024-03-10 15:03:11 - MAP@1: 0.0033\n",
      "2024-03-10 15:03:11 - MAP@3: 0.0044\n",
      "2024-03-10 15:03:11 - MAP@5: 0.0053\n",
      "2024-03-10 15:03:11 - MAP@10: 0.0056\n",
      "2024-03-10 15:03:11 - MAP@100: 0.0059\n",
      "2024-03-10 15:03:11 - MAP@1000: 0.0071\n",
      "2024-03-10 15:03:11 - \n",
      "\n",
      "2024-03-10 15:03:11 - Recall@1: 0.0033\n",
      "2024-03-10 15:03:11 - Recall@3: 0.0067\n",
      "2024-03-10 15:03:11 - Recall@5: 0.0100\n",
      "2024-03-10 15:03:11 - Recall@10: 0.0133\n",
      "2024-03-10 15:03:11 - Recall@100: 0.0250\n",
      "2024-03-10 15:03:11 - Recall@1000: 0.4436\n",
      "2024-03-10 15:03:11 - \n",
      "\n",
      "2024-03-10 15:03:11 - P@1: 0.0033\n",
      "2024-03-10 15:03:11 - P@3: 0.0022\n",
      "2024-03-10 15:03:11 - P@5: 0.0020\n",
      "2024-03-10 15:03:11 - P@10: 0.0013\n",
      "2024-03-10 15:03:11 - P@100: 0.0003\n",
      "2024-03-10 15:03:11 - P@1000: 0.0005\n",
      "2024-03-10 15:03:11 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-4-steps-375\n",
      "2024-03-10 15:03:11 - Use pytorch device_name: mps\n",
      "2024-03-10 15:03:11 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:03:13 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:03:13 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:03:13 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:03:13 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:48<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:04:04 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:04:04 - \n",
      "\n",
      "2024-03-10 15:04:04 - NDCG@1: 0.0100\n",
      "2024-03-10 15:04:04 - NDCG@3: 0.0142\n",
      "2024-03-10 15:04:04 - NDCG@5: 0.0169\n",
      "2024-03-10 15:04:04 - NDCG@10: 0.0203\n",
      "2024-03-10 15:04:04 - NDCG@100: 0.0544\n",
      "2024-03-10 15:04:04 - NDCG@1000: 0.1203\n",
      "2024-03-10 15:04:04 - \n",
      "\n",
      "2024-03-10 15:04:04 - MAP@1: 0.0100\n",
      "2024-03-10 15:04:04 - MAP@3: 0.0133\n",
      "2024-03-10 15:04:04 - MAP@5: 0.0148\n",
      "2024-03-10 15:04:04 - MAP@10: 0.0162\n",
      "2024-03-10 15:04:04 - MAP@100: 0.0224\n",
      "2024-03-10 15:04:04 - MAP@1000: 0.0245\n",
      "2024-03-10 15:04:04 - \n",
      "\n",
      "2024-03-10 15:04:04 - Recall@1: 0.0100\n",
      "2024-03-10 15:04:04 - Recall@3: 0.0167\n",
      "2024-03-10 15:04:04 - Recall@5: 0.0233\n",
      "2024-03-10 15:04:04 - Recall@10: 0.0323\n",
      "2024-03-10 15:04:04 - Recall@100: 0.1986\n",
      "2024-03-10 15:04:04 - Recall@1000: 0.7229\n",
      "2024-03-10 15:04:04 - \n",
      "\n",
      "2024-03-10 15:04:04 - P@1: 0.0100\n",
      "2024-03-10 15:04:04 - P@3: 0.0056\n",
      "2024-03-10 15:04:04 - P@5: 0.0047\n",
      "2024-03-10 15:04:04 - P@10: 0.0037\n",
      "2024-03-10 15:04:04 - P@100: 0.0022\n",
      "2024-03-10 15:04:04 - P@1000: 0.0008\n",
      "2024-03-10 15:04:04 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-4-steps-51\n",
      "2024-03-10 15:04:04 - Use pytorch device_name: mps\n",
      "2024-03-10 15:04:04 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:04:07 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:04:07 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:04:07 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:04:07 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [01:01<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:05:11 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:05:11 - \n",
      "\n",
      "2024-03-10 15:05:11 - NDCG@1: 0.0000\n",
      "2024-03-10 15:05:11 - NDCG@3: 0.0021\n",
      "2024-03-10 15:05:11 - NDCG@5: 0.0021\n",
      "2024-03-10 15:05:11 - NDCG@10: 0.0033\n",
      "2024-03-10 15:05:11 - NDCG@100: 0.0060\n",
      "2024-03-10 15:05:11 - NDCG@1000: 0.0504\n",
      "2024-03-10 15:05:11 - \n",
      "\n",
      "2024-03-10 15:05:11 - MAP@1: 0.0000\n",
      "2024-03-10 15:05:11 - MAP@3: 0.0017\n",
      "2024-03-10 15:05:11 - MAP@5: 0.0017\n",
      "2024-03-10 15:05:11 - MAP@10: 0.0022\n",
      "2024-03-10 15:05:11 - MAP@100: 0.0028\n",
      "2024-03-10 15:05:11 - MAP@1000: 0.0039\n",
      "2024-03-10 15:05:11 - \n",
      "\n",
      "2024-03-10 15:05:11 - Recall@1: 0.0000\n",
      "2024-03-10 15:05:11 - Recall@3: 0.0033\n",
      "2024-03-10 15:05:11 - Recall@5: 0.0033\n",
      "2024-03-10 15:05:11 - Recall@10: 0.0067\n",
      "2024-03-10 15:05:11 - Recall@100: 0.0183\n",
      "2024-03-10 15:05:11 - Recall@1000: 0.3919\n",
      "2024-03-10 15:05:11 - \n",
      "\n",
      "2024-03-10 15:05:11 - P@1: 0.0000\n",
      "2024-03-10 15:05:11 - P@3: 0.0011\n",
      "2024-03-10 15:05:11 - P@5: 0.0007\n",
      "2024-03-10 15:05:11 - P@10: 0.0007\n",
      "2024-03-10 15:05:11 - P@100: 0.0002\n",
      "2024-03-10 15:05:11 - P@1000: 0.0004\n",
      "2024-03-10 15:05:11 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-5-steps-51\n",
      "2024-03-10 15:05:11 - Use pytorch device_name: mps\n",
      "2024-03-10 15:05:11 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:05:13 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:05:13 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:05:13 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:05:13 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [01:00<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:06:16 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:06:17 - \n",
      "\n",
      "2024-03-10 15:06:17 - NDCG@1: 0.0067\n",
      "2024-03-10 15:06:17 - NDCG@3: 0.0067\n",
      "2024-03-10 15:06:17 - NDCG@5: 0.0067\n",
      "2024-03-10 15:06:17 - NDCG@10: 0.0067\n",
      "2024-03-10 15:06:17 - NDCG@100: 0.0093\n",
      "2024-03-10 15:06:17 - NDCG@1000: 0.0498\n",
      "2024-03-10 15:06:17 - \n",
      "\n",
      "2024-03-10 15:06:17 - MAP@1: 0.0067\n",
      "2024-03-10 15:06:17 - MAP@3: 0.0067\n",
      "2024-03-10 15:06:17 - MAP@5: 0.0067\n",
      "2024-03-10 15:06:17 - MAP@10: 0.0067\n",
      "2024-03-10 15:06:17 - MAP@100: 0.0069\n",
      "2024-03-10 15:06:17 - MAP@1000: 0.0078\n",
      "2024-03-10 15:06:17 - \n",
      "\n",
      "2024-03-10 15:06:17 - Recall@1: 0.0067\n",
      "2024-03-10 15:06:17 - Recall@3: 0.0067\n",
      "2024-03-10 15:06:17 - Recall@5: 0.0067\n",
      "2024-03-10 15:06:17 - Recall@10: 0.0067\n",
      "2024-03-10 15:06:17 - Recall@100: 0.0217\n",
      "2024-03-10 15:06:17 - Recall@1000: 0.3701\n",
      "2024-03-10 15:06:17 - \n",
      "\n",
      "2024-03-10 15:06:17 - P@1: 0.0067\n",
      "2024-03-10 15:06:17 - P@3: 0.0022\n",
      "2024-03-10 15:06:17 - P@5: 0.0013\n",
      "2024-03-10 15:06:17 - P@10: 0.0007\n",
      "2024-03-10 15:06:17 - P@100: 0.0002\n",
      "2024-03-10 15:06:17 - P@1000: 0.0004\n",
      "2024-03-10 15:06:17 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-12-steps-375\n",
      "2024-03-10 15:06:17 - Use pytorch device_name: mps\n",
      "2024-03-10 15:06:17 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:06:19 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:06:19 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:06:19 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:06:19 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:53<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:07:15 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:07:15 - \n",
      "\n",
      "2024-03-10 15:07:15 - NDCG@1: 0.0367\n",
      "2024-03-10 15:07:15 - NDCG@3: 0.0655\n",
      "2024-03-10 15:07:15 - NDCG@5: 0.0785\n",
      "2024-03-10 15:07:15 - NDCG@10: 0.0968\n",
      "2024-03-10 15:07:15 - NDCG@100: 0.1708\n",
      "2024-03-10 15:07:15 - NDCG@1000: 0.2200\n",
      "2024-03-10 15:07:15 - \n",
      "\n",
      "2024-03-10 15:07:15 - MAP@1: 0.0367\n",
      "2024-03-10 15:07:15 - MAP@3: 0.0578\n",
      "2024-03-10 15:07:15 - MAP@5: 0.0650\n",
      "2024-03-10 15:07:15 - MAP@10: 0.0721\n",
      "2024-03-10 15:07:15 - MAP@100: 0.0845\n",
      "2024-03-10 15:07:15 - MAP@1000: 0.0862\n",
      "2024-03-10 15:07:15 - \n",
      "\n",
      "2024-03-10 15:07:15 - Recall@1: 0.0367\n",
      "2024-03-10 15:07:15 - Recall@3: 0.0858\n",
      "2024-03-10 15:07:15 - Recall@5: 0.1156\n",
      "2024-03-10 15:07:15 - Recall@10: 0.1723\n",
      "2024-03-10 15:07:15 - Recall@100: 0.5431\n",
      "2024-03-10 15:07:15 - Recall@1000: 0.9330\n",
      "2024-03-10 15:07:15 - \n",
      "\n",
      "2024-03-10 15:07:15 - P@1: 0.0367\n",
      "2024-03-10 15:07:15 - P@3: 0.0311\n",
      "2024-03-10 15:07:15 - P@5: 0.0260\n",
      "2024-03-10 15:07:15 - P@10: 0.0197\n",
      "2024-03-10 15:07:15 - P@100: 0.0062\n",
      "2024-03-10 15:07:15 - P@1000: 0.0010\n",
      "2024-03-10 15:07:15 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-3-steps-375\n",
      "2024-03-10 15:07:15 - Use pytorch device_name: mps\n",
      "2024-03-10 15:07:16 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:07:18 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:07:18 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:07:18 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:07:18 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:54<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:08:15 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:08:15 - \n",
      "\n",
      "2024-03-10 15:08:15 - NDCG@1: 0.0033\n",
      "2024-03-10 15:08:15 - NDCG@3: 0.0050\n",
      "2024-03-10 15:08:15 - NDCG@5: 0.0077\n",
      "2024-03-10 15:08:15 - NDCG@10: 0.0097\n",
      "2024-03-10 15:08:15 - NDCG@100: 0.0355\n",
      "2024-03-10 15:08:15 - NDCG@1000: 0.1003\n",
      "2024-03-10 15:08:15 - \n",
      "\n",
      "2024-03-10 15:08:15 - MAP@1: 0.0033\n",
      "2024-03-10 15:08:15 - MAP@3: 0.0044\n",
      "2024-03-10 15:08:15 - MAP@5: 0.0059\n",
      "2024-03-10 15:08:15 - MAP@10: 0.0066\n",
      "2024-03-10 15:08:15 - MAP@100: 0.0109\n",
      "2024-03-10 15:08:15 - MAP@1000: 0.0129\n",
      "2024-03-10 15:08:15 - \n",
      "\n",
      "2024-03-10 15:08:15 - Recall@1: 0.0033\n",
      "2024-03-10 15:08:15 - Recall@3: 0.0067\n",
      "2024-03-10 15:08:15 - Recall@5: 0.0133\n",
      "2024-03-10 15:08:15 - Recall@10: 0.0200\n",
      "2024-03-10 15:08:15 - Recall@100: 0.1479\n",
      "2024-03-10 15:08:15 - Recall@1000: 0.6712\n",
      "2024-03-10 15:08:15 - \n",
      "\n",
      "2024-03-10 15:08:15 - P@1: 0.0033\n",
      "2024-03-10 15:08:15 - P@3: 0.0022\n",
      "2024-03-10 15:08:15 - P@5: 0.0027\n",
      "2024-03-10 15:08:15 - P@10: 0.0020\n",
      "2024-03-10 15:08:15 - P@100: 0.0016\n",
      "2024-03-10 15:08:15 - P@1000: 0.0008\n",
      "2024-03-10 15:08:15 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-8-steps-375\n",
      "2024-03-10 15:08:15 - Use pytorch device_name: mps\n",
      "2024-03-10 15:08:15 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:08:18 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:08:18 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:08:18 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:08:18 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:59<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:09:19 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:09:20 - \n",
      "\n",
      "2024-03-10 15:09:20 - NDCG@1: 0.0167\n",
      "2024-03-10 15:09:20 - NDCG@3: 0.0230\n",
      "2024-03-10 15:09:20 - NDCG@5: 0.0343\n",
      "2024-03-10 15:09:20 - NDCG@10: 0.0492\n",
      "2024-03-10 15:09:20 - NDCG@100: 0.0979\n",
      "2024-03-10 15:09:20 - NDCG@1000: 0.1622\n",
      "2024-03-10 15:09:20 - \n",
      "\n",
      "2024-03-10 15:09:20 - MAP@1: 0.0167\n",
      "2024-03-10 15:09:20 - MAP@3: 0.0217\n",
      "2024-03-10 15:09:20 - MAP@5: 0.0274\n",
      "2024-03-10 15:09:20 - MAP@10: 0.0333\n",
      "2024-03-10 15:09:20 - MAP@100: 0.0407\n",
      "2024-03-10 15:09:20 - MAP@1000: 0.0429\n",
      "2024-03-10 15:09:20 - \n",
      "\n",
      "2024-03-10 15:09:20 - Recall@1: 0.0167\n",
      "2024-03-10 15:09:20 - Recall@3: 0.0267\n",
      "2024-03-10 15:09:20 - Recall@5: 0.0536\n",
      "2024-03-10 15:09:20 - Recall@10: 0.1004\n",
      "2024-03-10 15:09:20 - Recall@100: 0.3536\n",
      "2024-03-10 15:09:20 - Recall@1000: 0.8673\n",
      "2024-03-10 15:09:20 - \n",
      "\n",
      "2024-03-10 15:09:20 - P@1: 0.0167\n",
      "2024-03-10 15:09:20 - P@3: 0.0089\n",
      "2024-03-10 15:09:20 - P@5: 0.0120\n",
      "2024-03-10 15:09:20 - P@10: 0.0113\n",
      "2024-03-10 15:09:20 - P@100: 0.0039\n",
      "2024-03-10 15:09:20 - P@1000: 0.0010\n",
      "2024-03-10 15:09:20 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-14-steps-51\n",
      "2024-03-10 15:09:20 - Use pytorch device_name: mps\n",
      "2024-03-10 15:09:20 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:09:22 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:09:22 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:09:22 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:09:22 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:59<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:10:24 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:10:24 - \n",
      "\n",
      "2024-03-10 15:10:24 - NDCG@1: 0.0067\n",
      "2024-03-10 15:10:24 - NDCG@3: 0.0067\n",
      "2024-03-10 15:10:24 - NDCG@5: 0.0067\n",
      "2024-03-10 15:10:24 - NDCG@10: 0.0077\n",
      "2024-03-10 15:10:24 - NDCG@100: 0.0135\n",
      "2024-03-10 15:10:24 - NDCG@1000: 0.0628\n",
      "2024-03-10 15:10:24 - \n",
      "\n",
      "2024-03-10 15:10:24 - MAP@1: 0.0067\n",
      "2024-03-10 15:10:24 - MAP@3: 0.0067\n",
      "2024-03-10 15:10:24 - MAP@5: 0.0067\n",
      "2024-03-10 15:10:24 - MAP@10: 0.0070\n",
      "2024-03-10 15:10:24 - MAP@100: 0.0079\n",
      "2024-03-10 15:10:24 - MAP@1000: 0.0092\n",
      "2024-03-10 15:10:24 - \n",
      "\n",
      "2024-03-10 15:10:24 - Recall@1: 0.0067\n",
      "2024-03-10 15:10:24 - Recall@3: 0.0067\n",
      "2024-03-10 15:10:24 - Recall@5: 0.0067\n",
      "2024-03-10 15:10:24 - Recall@10: 0.0100\n",
      "2024-03-10 15:10:24 - Recall@100: 0.0394\n",
      "2024-03-10 15:10:24 - Recall@1000: 0.4526\n",
      "2024-03-10 15:10:24 - \n",
      "\n",
      "2024-03-10 15:10:24 - P@1: 0.0067\n",
      "2024-03-10 15:10:24 - P@3: 0.0022\n",
      "2024-03-10 15:10:24 - P@5: 0.0013\n",
      "2024-03-10 15:10:24 - P@10: 0.0010\n",
      "2024-03-10 15:10:24 - P@100: 0.0004\n",
      "2024-03-10 15:10:24 - P@1000: 0.0005\n",
      "2024-03-10 15:10:24 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-15-steps-51\n",
      "2024-03-10 15:10:24 - Use pytorch device_name: mps\n",
      "2024-03-10 15:10:24 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:10:27 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:10:27 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:10:27 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:10:27 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [01:02<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:11:31 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:11:31 - \n",
      "\n",
      "2024-03-10 15:11:31 - NDCG@1: 0.0067\n",
      "2024-03-10 15:11:31 - NDCG@3: 0.0067\n",
      "2024-03-10 15:11:31 - NDCG@5: 0.0081\n",
      "2024-03-10 15:11:31 - NDCG@10: 0.0081\n",
      "2024-03-10 15:11:31 - NDCG@100: 0.0123\n",
      "2024-03-10 15:11:31 - NDCG@1000: 0.0609\n",
      "2024-03-10 15:11:31 - \n",
      "\n",
      "2024-03-10 15:11:31 - MAP@1: 0.0067\n",
      "2024-03-10 15:11:31 - MAP@3: 0.0067\n",
      "2024-03-10 15:11:31 - MAP@5: 0.0075\n",
      "2024-03-10 15:11:31 - MAP@10: 0.0075\n",
      "2024-03-10 15:11:31 - MAP@100: 0.0080\n",
      "2024-03-10 15:11:31 - MAP@1000: 0.0092\n",
      "2024-03-10 15:11:31 - \n",
      "\n",
      "2024-03-10 15:11:31 - Recall@1: 0.0067\n",
      "2024-03-10 15:11:31 - Recall@3: 0.0067\n",
      "2024-03-10 15:11:31 - Recall@5: 0.0100\n",
      "2024-03-10 15:11:31 - Recall@10: 0.0100\n",
      "2024-03-10 15:11:31 - Recall@100: 0.0328\n",
      "2024-03-10 15:11:31 - Recall@1000: 0.4433\n",
      "2024-03-10 15:11:31 - \n",
      "\n",
      "2024-03-10 15:11:31 - P@1: 0.0067\n",
      "2024-03-10 15:11:31 - P@3: 0.0022\n",
      "2024-03-10 15:11:31 - P@5: 0.0020\n",
      "2024-03-10 15:11:31 - P@10: 0.0010\n",
      "2024-03-10 15:11:31 - P@100: 0.0004\n",
      "2024-03-10 15:11:31 - P@1000: 0.0005\n",
      "2024-03-10 15:11:31 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-5-steps-375\n",
      "2024-03-10 15:11:32 - Use pytorch device_name: mps\n",
      "2024-03-10 15:11:32 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:11:34 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:11:34 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:11:34 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:11:34 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:58<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:12:35 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:12:35 - \n",
      "\n",
      "2024-03-10 15:12:35 - NDCG@1: 0.0133\n",
      "2024-03-10 15:12:35 - NDCG@3: 0.0196\n",
      "2024-03-10 15:12:35 - NDCG@5: 0.0228\n",
      "2024-03-10 15:12:35 - NDCG@10: 0.0318\n",
      "2024-03-10 15:12:35 - NDCG@100: 0.0750\n",
      "2024-03-10 15:12:35 - NDCG@1000: 0.1384\n",
      "2024-03-10 15:12:35 - \n",
      "\n",
      "2024-03-10 15:12:35 - MAP@1: 0.0133\n",
      "2024-03-10 15:12:35 - MAP@3: 0.0183\n",
      "2024-03-10 15:12:35 - MAP@5: 0.0200\n",
      "2024-03-10 15:12:35 - MAP@10: 0.0234\n",
      "2024-03-10 15:12:35 - MAP@100: 0.0309\n",
      "2024-03-10 15:12:35 - MAP@1000: 0.0329\n",
      "2024-03-10 15:12:35 - \n",
      "\n",
      "2024-03-10 15:12:35 - Recall@1: 0.0133\n",
      "2024-03-10 15:12:35 - Recall@3: 0.0233\n",
      "2024-03-10 15:12:35 - Recall@5: 0.0307\n",
      "2024-03-10 15:12:35 - Recall@10: 0.0590\n",
      "2024-03-10 15:12:35 - Recall@100: 0.2738\n",
      "2024-03-10 15:12:35 - Recall@1000: 0.7852\n",
      "2024-03-10 15:12:35 - \n",
      "\n",
      "2024-03-10 15:12:35 - P@1: 0.0133\n",
      "2024-03-10 15:12:35 - P@3: 0.0078\n",
      "2024-03-10 15:12:35 - P@5: 0.0067\n",
      "2024-03-10 15:12:35 - P@10: 0.0063\n",
      "2024-03-10 15:12:35 - P@100: 0.0030\n",
      "2024-03-10 15:12:35 - P@1000: 0.0009\n",
      "2024-03-10 15:12:35 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-11-steps-375\n",
      "2024-03-10 15:12:36 - Use pytorch device_name: mps\n",
      "2024-03-10 15:12:36 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:12:38 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:12:38 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:12:38 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:12:38 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [01:03<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:13:44 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:13:44 - \n",
      "\n",
      "2024-03-10 15:13:44 - NDCG@1: 0.0267\n",
      "2024-03-10 15:13:44 - NDCG@3: 0.0442\n",
      "2024-03-10 15:13:44 - NDCG@5: 0.0571\n",
      "2024-03-10 15:13:44 - NDCG@10: 0.0742\n",
      "2024-03-10 15:13:44 - NDCG@100: 0.1356\n",
      "2024-03-10 15:13:44 - NDCG@1000: 0.1942\n",
      "2024-03-10 15:13:44 - \n",
      "\n",
      "2024-03-10 15:13:44 - MAP@1: 0.0267\n",
      "2024-03-10 15:13:44 - MAP@3: 0.0394\n",
      "2024-03-10 15:13:44 - MAP@5: 0.0462\n",
      "2024-03-10 15:13:44 - MAP@10: 0.0531\n",
      "2024-03-10 15:13:44 - MAP@100: 0.0630\n",
      "2024-03-10 15:13:44 - MAP@1000: 0.0651\n",
      "2024-03-10 15:13:44 - \n",
      "\n",
      "2024-03-10 15:13:44 - Recall@1: 0.0267\n",
      "2024-03-10 15:13:44 - Recall@3: 0.0558\n",
      "2024-03-10 15:13:44 - Recall@5: 0.0864\n",
      "2024-03-10 15:13:44 - Recall@10: 0.1396\n",
      "2024-03-10 15:13:44 - Recall@100: 0.4498\n",
      "2024-03-10 15:13:44 - Recall@1000: 0.9157\n",
      "2024-03-10 15:13:44 - \n",
      "\n",
      "2024-03-10 15:13:44 - P@1: 0.0267\n",
      "2024-03-10 15:13:44 - P@3: 0.0200\n",
      "2024-03-10 15:13:44 - P@5: 0.0193\n",
      "2024-03-10 15:13:44 - P@10: 0.0157\n",
      "2024-03-10 15:13:44 - P@100: 0.0052\n",
      "2024-03-10 15:13:44 - P@1000: 0.0010\n",
      "2024-03-10 15:13:44 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-0-steps-51\n",
      "2024-03-10 15:13:44 - Use pytorch device_name: mps\n",
      "2024-03-10 15:13:44 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:13:47 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:13:47 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:13:47 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:13:47 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:14:45 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:14:45 - \n",
      "\n",
      "2024-03-10 15:14:45 - NDCG@1: 0.0033\n",
      "2024-03-10 15:14:45 - NDCG@3: 0.0033\n",
      "2024-03-10 15:14:45 - NDCG@5: 0.0033\n",
      "2024-03-10 15:14:45 - NDCG@10: 0.0044\n",
      "2024-03-10 15:14:45 - NDCG@100: 0.0047\n",
      "2024-03-10 15:14:45 - NDCG@1000: 0.0268\n",
      "2024-03-10 15:14:45 - \n",
      "\n",
      "2024-03-10 15:14:45 - MAP@1: 0.0033\n",
      "2024-03-10 15:14:45 - MAP@3: 0.0033\n",
      "2024-03-10 15:14:45 - MAP@5: 0.0033\n",
      "2024-03-10 15:14:45 - MAP@10: 0.0037\n",
      "2024-03-10 15:14:45 - MAP@100: 0.0038\n",
      "2024-03-10 15:14:45 - MAP@1000: 0.0042\n",
      "2024-03-10 15:14:45 - \n",
      "\n",
      "2024-03-10 15:14:45 - Recall@1: 0.0033\n",
      "2024-03-10 15:14:45 - Recall@3: 0.0033\n",
      "2024-03-10 15:14:45 - Recall@5: 0.0033\n",
      "2024-03-10 15:14:45 - Recall@10: 0.0067\n",
      "2024-03-10 15:14:45 - Recall@100: 0.0083\n",
      "2024-03-10 15:14:45 - Recall@1000: 0.2052\n",
      "2024-03-10 15:14:45 - \n",
      "\n",
      "2024-03-10 15:14:45 - P@1: 0.0033\n",
      "2024-03-10 15:14:45 - P@3: 0.0011\n",
      "2024-03-10 15:14:45 - P@5: 0.0007\n",
      "2024-03-10 15:14:45 - P@10: 0.0007\n",
      "2024-03-10 15:14:45 - P@100: 0.0001\n",
      "2024-03-10 15:14:45 - P@1000: 0.0002\n",
      "2024-03-10 15:14:45 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-1-steps-51\n",
      "2024-03-10 15:14:45 - Use pytorch device_name: mps\n",
      "2024-03-10 15:14:45 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:14:47 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:14:47 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:14:47 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:14:47 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:53<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:15:44 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:15:44 - \n",
      "\n",
      "2024-03-10 15:15:44 - NDCG@1: 0.0000\n",
      "2024-03-10 15:15:44 - NDCG@3: 0.0000\n",
      "2024-03-10 15:15:44 - NDCG@5: 0.0000\n",
      "2024-03-10 15:15:44 - NDCG@10: 0.0010\n",
      "2024-03-10 15:15:44 - NDCG@100: 0.0033\n",
      "2024-03-10 15:15:44 - NDCG@1000: 0.0324\n",
      "2024-03-10 15:15:44 - \n",
      "\n",
      "2024-03-10 15:15:44 - MAP@1: 0.0000\n",
      "2024-03-10 15:15:44 - MAP@3: 0.0000\n",
      "2024-03-10 15:15:44 - MAP@5: 0.0000\n",
      "2024-03-10 15:15:44 - MAP@10: 0.0004\n",
      "2024-03-10 15:15:44 - MAP@100: 0.0007\n",
      "2024-03-10 15:15:44 - MAP@1000: 0.0013\n",
      "2024-03-10 15:15:44 - \n",
      "\n",
      "2024-03-10 15:15:44 - Recall@1: 0.0000\n",
      "2024-03-10 15:15:44 - Recall@3: 0.0000\n",
      "2024-03-10 15:15:44 - Recall@5: 0.0000\n",
      "2024-03-10 15:15:44 - Recall@10: 0.0033\n",
      "2024-03-10 15:15:44 - Recall@100: 0.0150\n",
      "2024-03-10 15:15:44 - Recall@1000: 0.2688\n",
      "2024-03-10 15:15:44 - \n",
      "\n",
      "2024-03-10 15:15:44 - P@1: 0.0000\n",
      "2024-03-10 15:15:44 - P@3: 0.0000\n",
      "2024-03-10 15:15:44 - P@5: 0.0000\n",
      "2024-03-10 15:15:44 - P@10: 0.0003\n",
      "2024-03-10 15:15:44 - P@100: 0.0002\n",
      "2024-03-10 15:15:44 - P@1000: 0.0003\n",
      "2024-03-10 15:15:44 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-0-steps-375\n",
      "2024-03-10 15:15:44 - Use pytorch device_name: mps\n",
      "2024-03-10 15:15:44 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:15:47 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:15:47 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:15:47 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:15:47 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:57<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:16:46 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:16:47 - \n",
      "\n",
      "2024-03-10 15:16:47 - NDCG@1: 0.0033\n",
      "2024-03-10 15:16:47 - NDCG@3: 0.0033\n",
      "2024-03-10 15:16:47 - NDCG@5: 0.0033\n",
      "2024-03-10 15:16:47 - NDCG@10: 0.0033\n",
      "2024-03-10 15:16:47 - NDCG@100: 0.0067\n",
      "2024-03-10 15:16:47 - NDCG@1000: 0.0486\n",
      "2024-03-10 15:16:47 - \n",
      "\n",
      "2024-03-10 15:16:47 - MAP@1: 0.0033\n",
      "2024-03-10 15:16:47 - MAP@3: 0.0033\n",
      "2024-03-10 15:16:47 - MAP@5: 0.0033\n",
      "2024-03-10 15:16:47 - MAP@10: 0.0033\n",
      "2024-03-10 15:16:47 - MAP@100: 0.0037\n",
      "2024-03-10 15:16:47 - MAP@1000: 0.0045\n",
      "2024-03-10 15:16:47 - \n",
      "\n",
      "2024-03-10 15:16:47 - Recall@1: 0.0033\n",
      "2024-03-10 15:16:47 - Recall@3: 0.0033\n",
      "2024-03-10 15:16:47 - Recall@5: 0.0033\n",
      "2024-03-10 15:16:47 - Recall@10: 0.0033\n",
      "2024-03-10 15:16:47 - Recall@100: 0.0223\n",
      "2024-03-10 15:16:47 - Recall@1000: 0.3861\n",
      "2024-03-10 15:16:47 - \n",
      "\n",
      "2024-03-10 15:16:47 - P@1: 0.0033\n",
      "2024-03-10 15:16:47 - P@3: 0.0011\n",
      "2024-03-10 15:16:47 - P@5: 0.0007\n",
      "2024-03-10 15:16:47 - P@10: 0.0003\n",
      "2024-03-10 15:16:47 - P@100: 0.0003\n",
      "2024-03-10 15:16:47 - P@1000: 0.0004\n",
      "2024-03-10 15:16:47 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-10-steps-51\n",
      "2024-03-10 15:16:47 - Use pytorch device_name: mps\n",
      "2024-03-10 15:16:47 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:16:49 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:16:49 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:16:49 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:16:49 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:56<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:17:48 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:17:48 - \n",
      "\n",
      "2024-03-10 15:17:48 - NDCG@1: 0.0100\n",
      "2024-03-10 15:17:48 - NDCG@3: 0.0100\n",
      "2024-03-10 15:17:48 - NDCG@5: 0.0100\n",
      "2024-03-10 15:17:48 - NDCG@10: 0.0100\n",
      "2024-03-10 15:17:48 - NDCG@100: 0.0128\n",
      "2024-03-10 15:17:48 - NDCG@1000: 0.0564\n",
      "2024-03-10 15:17:48 - \n",
      "\n",
      "2024-03-10 15:17:48 - MAP@1: 0.0100\n",
      "2024-03-10 15:17:48 - MAP@3: 0.0100\n",
      "2024-03-10 15:17:48 - MAP@5: 0.0100\n",
      "2024-03-10 15:17:48 - MAP@10: 0.0100\n",
      "2024-03-10 15:17:48 - MAP@100: 0.0104\n",
      "2024-03-10 15:17:48 - MAP@1000: 0.0115\n",
      "2024-03-10 15:17:48 - \n",
      "\n",
      "2024-03-10 15:17:48 - Recall@1: 0.0100\n",
      "2024-03-10 15:17:48 - Recall@3: 0.0100\n",
      "2024-03-10 15:17:48 - Recall@5: 0.0100\n",
      "2024-03-10 15:17:48 - Recall@10: 0.0100\n",
      "2024-03-10 15:17:48 - Recall@100: 0.0250\n",
      "2024-03-10 15:17:48 - Recall@1000: 0.3885\n",
      "2024-03-10 15:17:48 - \n",
      "\n",
      "2024-03-10 15:17:48 - P@1: 0.0100\n",
      "2024-03-10 15:17:48 - P@3: 0.0033\n",
      "2024-03-10 15:17:48 - P@5: 0.0020\n",
      "2024-03-10 15:17:48 - P@10: 0.0010\n",
      "2024-03-10 15:17:48 - P@100: 0.0003\n",
      "2024-03-10 15:17:48 - P@1000: 0.0004\n",
      "2024-03-10 15:17:48 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-11-steps-51\n",
      "2024-03-10 15:17:49 - Use pytorch device_name: mps\n",
      "2024-03-10 15:17:49 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:17:51 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:17:51 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:17:51 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:17:51 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:18:48 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:18:49 - \n",
      "\n",
      "2024-03-10 15:18:49 - NDCG@1: 0.0067\n",
      "2024-03-10 15:18:49 - NDCG@3: 0.0088\n",
      "2024-03-10 15:18:49 - NDCG@5: 0.0088\n",
      "2024-03-10 15:18:49 - NDCG@10: 0.0097\n",
      "2024-03-10 15:18:49 - NDCG@100: 0.0132\n",
      "2024-03-10 15:18:49 - NDCG@1000: 0.0591\n",
      "2024-03-10 15:18:49 - \n",
      "\n",
      "2024-03-10 15:18:49 - MAP@1: 0.0067\n",
      "2024-03-10 15:18:49 - MAP@3: 0.0083\n",
      "2024-03-10 15:18:49 - MAP@5: 0.0083\n",
      "2024-03-10 15:18:49 - MAP@10: 0.0087\n",
      "2024-03-10 15:18:49 - MAP@100: 0.0092\n",
      "2024-03-10 15:18:49 - MAP@1000: 0.0103\n",
      "2024-03-10 15:18:49 - \n",
      "\n",
      "2024-03-10 15:18:49 - Recall@1: 0.0067\n",
      "2024-03-10 15:18:49 - Recall@3: 0.0100\n",
      "2024-03-10 15:18:49 - Recall@5: 0.0100\n",
      "2024-03-10 15:18:49 - Recall@10: 0.0133\n",
      "2024-03-10 15:18:49 - Recall@100: 0.0317\n",
      "2024-03-10 15:18:49 - Recall@1000: 0.4142\n",
      "2024-03-10 15:18:49 - \n",
      "\n",
      "2024-03-10 15:18:49 - P@1: 0.0067\n",
      "2024-03-10 15:18:49 - P@3: 0.0033\n",
      "2024-03-10 15:18:49 - P@5: 0.0020\n",
      "2024-03-10 15:18:49 - P@10: 0.0013\n",
      "2024-03-10 15:18:49 - P@100: 0.0003\n",
      "2024-03-10 15:18:49 - P@1000: 0.0005\n",
      "2024-03-10 15:18:49 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-6-steps-375\n",
      "2024-03-10 15:18:49 - Use pytorch device_name: mps\n",
      "2024-03-10 15:18:49 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:18:51 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:18:51 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:18:51 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:18:51 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:56<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:19:49 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:19:50 - \n",
      "\n",
      "2024-03-10 15:19:50 - NDCG@1: 0.0133\n",
      "2024-03-10 15:19:50 - NDCG@3: 0.0217\n",
      "2024-03-10 15:19:50 - NDCG@5: 0.0235\n",
      "2024-03-10 15:19:50 - NDCG@10: 0.0392\n",
      "2024-03-10 15:19:50 - NDCG@100: 0.0838\n",
      "2024-03-10 15:19:50 - NDCG@1000: 0.1477\n",
      "2024-03-10 15:19:50 - \n",
      "\n",
      "2024-03-10 15:19:50 - MAP@1: 0.0133\n",
      "2024-03-10 15:19:50 - MAP@3: 0.0200\n",
      "2024-03-10 15:19:50 - MAP@5: 0.0208\n",
      "2024-03-10 15:19:50 - MAP@10: 0.0272\n",
      "2024-03-10 15:19:50 - MAP@100: 0.0345\n",
      "2024-03-10 15:19:50 - MAP@1000: 0.0366\n",
      "2024-03-10 15:19:50 - \n",
      "\n",
      "2024-03-10 15:19:50 - Recall@1: 0.0133\n",
      "2024-03-10 15:19:50 - Recall@3: 0.0267\n",
      "2024-03-10 15:19:50 - Recall@5: 0.0307\n",
      "2024-03-10 15:19:50 - Recall@10: 0.0784\n",
      "2024-03-10 15:19:50 - Recall@100: 0.3030\n",
      "2024-03-10 15:19:50 - Recall@1000: 0.8157\n",
      "2024-03-10 15:19:50 - \n",
      "\n",
      "2024-03-10 15:19:50 - P@1: 0.0133\n",
      "2024-03-10 15:19:50 - P@3: 0.0089\n",
      "2024-03-10 15:19:50 - P@5: 0.0067\n",
      "2024-03-10 15:19:50 - P@10: 0.0087\n",
      "2024-03-10 15:19:50 - P@100: 0.0034\n",
      "2024-03-10 15:19:50 - P@1000: 0.0009\n",
      "2024-03-10 15:19:50 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-10-steps-375\n",
      "2024-03-10 15:19:50 - Use pytorch device_name: mps\n",
      "2024-03-10 15:19:50 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:19:53 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:19:53 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:19:53 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:19:53 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:57<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:20:53 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:20:53 - \n",
      "\n",
      "2024-03-10 15:20:53 - NDCG@1: 0.0267\n",
      "2024-03-10 15:20:53 - NDCG@3: 0.0451\n",
      "2024-03-10 15:20:53 - NDCG@5: 0.0574\n",
      "2024-03-10 15:20:53 - NDCG@10: 0.0735\n",
      "2024-03-10 15:20:53 - NDCG@100: 0.1341\n",
      "2024-03-10 15:20:53 - NDCG@1000: 0.1922\n",
      "2024-03-10 15:20:53 - \n",
      "\n",
      "2024-03-10 15:20:53 - MAP@1: 0.0267\n",
      "2024-03-10 15:20:53 - MAP@3: 0.0406\n",
      "2024-03-10 15:20:53 - MAP@5: 0.0474\n",
      "2024-03-10 15:20:53 - MAP@10: 0.0539\n",
      "2024-03-10 15:20:53 - MAP@100: 0.0638\n",
      "2024-03-10 15:20:53 - MAP@1000: 0.0658\n",
      "2024-03-10 15:20:53 - \n",
      "\n",
      "2024-03-10 15:20:53 - Recall@1: 0.0267\n",
      "2024-03-10 15:20:53 - Recall@3: 0.0558\n",
      "2024-03-10 15:20:53 - Recall@5: 0.0829\n",
      "2024-03-10 15:20:53 - Recall@10: 0.1329\n",
      "2024-03-10 15:20:53 - Recall@100: 0.4381\n",
      "2024-03-10 15:20:53 - Recall@1000: 0.8963\n",
      "2024-03-10 15:20:53 - \n",
      "\n",
      "2024-03-10 15:20:53 - P@1: 0.0267\n",
      "2024-03-10 15:20:53 - P@3: 0.0200\n",
      "2024-03-10 15:20:53 - P@5: 0.0200\n",
      "2024-03-10 15:20:53 - P@10: 0.0150\n",
      "2024-03-10 15:20:53 - P@100: 0.0051\n",
      "2024-03-10 15:20:53 - P@1000: 0.0010\n",
      "2024-03-10 15:20:53 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-17-steps-51\n",
      "2024-03-10 15:20:54 - Use pytorch device_name: mps\n",
      "2024-03-10 15:20:54 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:20:56 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:20:56 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:20:56 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:20:56 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:56<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:21:55 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:21:55 - \n",
      "\n",
      "2024-03-10 15:21:55 - NDCG@1: 0.0067\n",
      "2024-03-10 15:21:55 - NDCG@3: 0.0067\n",
      "2024-03-10 15:21:55 - NDCG@5: 0.0067\n",
      "2024-03-10 15:21:55 - NDCG@10: 0.0089\n",
      "2024-03-10 15:21:55 - NDCG@100: 0.0121\n",
      "2024-03-10 15:21:55 - NDCG@1000: 0.0619\n",
      "2024-03-10 15:21:55 - \n",
      "\n",
      "2024-03-10 15:21:55 - MAP@1: 0.0067\n",
      "2024-03-10 15:21:55 - MAP@3: 0.0067\n",
      "2024-03-10 15:21:55 - MAP@5: 0.0067\n",
      "2024-03-10 15:21:55 - MAP@10: 0.0076\n",
      "2024-03-10 15:21:55 - MAP@100: 0.0079\n",
      "2024-03-10 15:21:55 - MAP@1000: 0.0091\n",
      "2024-03-10 15:21:55 - \n",
      "\n",
      "2024-03-10 15:21:55 - Recall@1: 0.0067\n",
      "2024-03-10 15:21:55 - Recall@3: 0.0067\n",
      "2024-03-10 15:21:55 - Recall@5: 0.0067\n",
      "2024-03-10 15:21:55 - Recall@10: 0.0133\n",
      "2024-03-10 15:21:55 - Recall@100: 0.0317\n",
      "2024-03-10 15:21:55 - Recall@1000: 0.4547\n",
      "2024-03-10 15:21:55 - \n",
      "\n",
      "2024-03-10 15:21:55 - P@1: 0.0067\n",
      "2024-03-10 15:21:55 - P@3: 0.0022\n",
      "2024-03-10 15:21:55 - P@5: 0.0013\n",
      "2024-03-10 15:21:55 - P@10: 0.0013\n",
      "2024-03-10 15:21:55 - P@100: 0.0003\n",
      "2024-03-10 15:21:55 - P@1000: 0.0005\n",
      "2024-03-10 15:21:55 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-16-steps-51\n",
      "2024-03-10 15:21:55 - Use pytorch device_name: mps\n",
      "2024-03-10 15:21:55 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:21:58 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:21:58 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:21:58 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:21:58 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:54<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:22:54 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:22:55 - \n",
      "\n",
      "2024-03-10 15:22:55 - NDCG@1: 0.0067\n",
      "2024-03-10 15:22:55 - NDCG@3: 0.0067\n",
      "2024-03-10 15:22:55 - NDCG@5: 0.0067\n",
      "2024-03-10 15:22:55 - NDCG@10: 0.0067\n",
      "2024-03-10 15:22:55 - NDCG@100: 0.0131\n",
      "2024-03-10 15:22:55 - NDCG@1000: 0.0609\n",
      "2024-03-10 15:22:55 - \n",
      "\n",
      "2024-03-10 15:22:55 - MAP@1: 0.0067\n",
      "2024-03-10 15:22:55 - MAP@3: 0.0067\n",
      "2024-03-10 15:22:55 - MAP@5: 0.0067\n",
      "2024-03-10 15:22:55 - MAP@10: 0.0067\n",
      "2024-03-10 15:22:55 - MAP@100: 0.0077\n",
      "2024-03-10 15:22:55 - MAP@1000: 0.0090\n",
      "2024-03-10 15:22:55 - \n",
      "\n",
      "2024-03-10 15:22:55 - Recall@1: 0.0067\n",
      "2024-03-10 15:22:55 - Recall@3: 0.0067\n",
      "2024-03-10 15:22:55 - Recall@5: 0.0067\n",
      "2024-03-10 15:22:55 - Recall@10: 0.0067\n",
      "2024-03-10 15:22:55 - Recall@100: 0.0383\n",
      "2024-03-10 15:22:55 - Recall@1000: 0.4343\n",
      "2024-03-10 15:22:55 - \n",
      "\n",
      "2024-03-10 15:22:55 - P@1: 0.0067\n",
      "2024-03-10 15:22:55 - P@3: 0.0022\n",
      "2024-03-10 15:22:55 - P@5: 0.0013\n",
      "2024-03-10 15:22:55 - P@10: 0.0007\n",
      "2024-03-10 15:22:55 - P@100: 0.0005\n",
      "2024-03-10 15:22:55 - P@1000: 0.0005\n",
      "2024-03-10 15:22:55 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-1-steps-375\n",
      "2024-03-10 15:22:55 - Use pytorch device_name: mps\n",
      "2024-03-10 15:22:55 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:22:57 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:22:57 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:22:57 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:22:57 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:23:55 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:23:55 - \n",
      "\n",
      "2024-03-10 15:23:55 - NDCG@1: 0.0033\n",
      "2024-03-10 15:23:55 - NDCG@3: 0.0033\n",
      "2024-03-10 15:23:55 - NDCG@5: 0.0033\n",
      "2024-03-10 15:23:55 - NDCG@10: 0.0033\n",
      "2024-03-10 15:23:55 - NDCG@100: 0.0189\n",
      "2024-03-10 15:23:55 - NDCG@1000: 0.0768\n",
      "2024-03-10 15:23:55 - \n",
      "\n",
      "2024-03-10 15:23:55 - MAP@1: 0.0033\n",
      "2024-03-10 15:23:55 - MAP@3: 0.0033\n",
      "2024-03-10 15:23:55 - MAP@5: 0.0033\n",
      "2024-03-10 15:23:55 - MAP@10: 0.0033\n",
      "2024-03-10 15:23:55 - MAP@100: 0.0055\n",
      "2024-03-10 15:23:55 - MAP@1000: 0.0070\n",
      "2024-03-10 15:23:55 - \n",
      "\n",
      "2024-03-10 15:23:55 - Recall@1: 0.0033\n",
      "2024-03-10 15:23:55 - Recall@3: 0.0033\n",
      "2024-03-10 15:23:55 - Recall@5: 0.0033\n",
      "2024-03-10 15:23:55 - Recall@10: 0.0033\n",
      "2024-03-10 15:23:55 - Recall@100: 0.0868\n",
      "2024-03-10 15:23:55 - Recall@1000: 0.5668\n",
      "2024-03-10 15:23:55 - \n",
      "\n",
      "2024-03-10 15:23:55 - P@1: 0.0033\n",
      "2024-03-10 15:23:55 - P@3: 0.0011\n",
      "2024-03-10 15:23:55 - P@5: 0.0007\n",
      "2024-03-10 15:23:55 - P@10: 0.0003\n",
      "2024-03-10 15:23:55 - P@100: 0.0009\n",
      "2024-03-10 15:23:55 - P@1000: 0.0006\n",
      "2024-03-10 15:23:55 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-7-steps-51\n",
      "2024-03-10 15:23:55 - Use pytorch device_name: mps\n",
      "2024-03-10 15:23:55 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:23:57 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:23:57 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:23:57 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:23:57 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:24:55 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:24:55 - \n",
      "\n",
      "2024-03-10 15:24:55 - NDCG@1: 0.0033\n",
      "2024-03-10 15:24:55 - NDCG@3: 0.0054\n",
      "2024-03-10 15:24:55 - NDCG@5: 0.0054\n",
      "2024-03-10 15:24:55 - NDCG@10: 0.0054\n",
      "2024-03-10 15:24:55 - NDCG@100: 0.0083\n",
      "2024-03-10 15:24:55 - NDCG@1000: 0.0540\n",
      "2024-03-10 15:24:55 - \n",
      "\n",
      "2024-03-10 15:24:55 - MAP@1: 0.0033\n",
      "2024-03-10 15:24:55 - MAP@3: 0.0050\n",
      "2024-03-10 15:24:55 - MAP@5: 0.0050\n",
      "2024-03-10 15:24:55 - MAP@10: 0.0050\n",
      "2024-03-10 15:24:55 - MAP@100: 0.0054\n",
      "2024-03-10 15:24:55 - MAP@1000: 0.0065\n",
      "2024-03-10 15:24:55 - \n",
      "\n",
      "2024-03-10 15:24:55 - Recall@1: 0.0033\n",
      "2024-03-10 15:24:55 - Recall@3: 0.0067\n",
      "2024-03-10 15:24:55 - Recall@5: 0.0067\n",
      "2024-03-10 15:24:55 - Recall@10: 0.0067\n",
      "2024-03-10 15:24:55 - Recall@100: 0.0217\n",
      "2024-03-10 15:24:55 - Recall@1000: 0.4095\n",
      "2024-03-10 15:24:55 - \n",
      "\n",
      "2024-03-10 15:24:55 - P@1: 0.0033\n",
      "2024-03-10 15:24:55 - P@3: 0.0022\n",
      "2024-03-10 15:24:55 - P@5: 0.0013\n",
      "2024-03-10 15:24:55 - P@10: 0.0007\n",
      "2024-03-10 15:24:55 - P@100: 0.0002\n",
      "2024-03-10 15:24:55 - P@1000: 0.0005\n",
      "2024-03-10 15:24:55 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-6-steps-51\n",
      "2024-03-10 15:24:55 - Use pytorch device_name: mps\n",
      "2024-03-10 15:24:55 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:24:58 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:24:58 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:24:58 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:24:58 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:25:55 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:25:56 - \n",
      "\n",
      "2024-03-10 15:25:56 - NDCG@1: 0.0033\n",
      "2024-03-10 15:25:56 - NDCG@3: 0.0054\n",
      "2024-03-10 15:25:56 - NDCG@5: 0.0054\n",
      "2024-03-10 15:25:56 - NDCG@10: 0.0064\n",
      "2024-03-10 15:25:56 - NDCG@100: 0.0097\n",
      "2024-03-10 15:25:56 - NDCG@1000: 0.0523\n",
      "2024-03-10 15:25:56 - \n",
      "\n",
      "2024-03-10 15:25:56 - MAP@1: 0.0033\n",
      "2024-03-10 15:25:56 - MAP@3: 0.0050\n",
      "2024-03-10 15:25:56 - MAP@5: 0.0050\n",
      "2024-03-10 15:25:56 - MAP@10: 0.0054\n",
      "2024-03-10 15:25:56 - MAP@100: 0.0057\n",
      "2024-03-10 15:25:56 - MAP@1000: 0.0067\n",
      "2024-03-10 15:25:56 - \n",
      "\n",
      "2024-03-10 15:25:56 - Recall@1: 0.0033\n",
      "2024-03-10 15:25:56 - Recall@3: 0.0067\n",
      "2024-03-10 15:25:56 - Recall@5: 0.0067\n",
      "2024-03-10 15:25:56 - Recall@10: 0.0100\n",
      "2024-03-10 15:25:56 - Recall@100: 0.0283\n",
      "2024-03-10 15:25:56 - Recall@1000: 0.3894\n",
      "2024-03-10 15:25:56 - \n",
      "\n",
      "2024-03-10 15:25:56 - P@1: 0.0033\n",
      "2024-03-10 15:25:56 - P@3: 0.0022\n",
      "2024-03-10 15:25:56 - P@5: 0.0013\n",
      "2024-03-10 15:25:56 - P@10: 0.0010\n",
      "2024-03-10 15:25:56 - P@100: 0.0003\n",
      "2024-03-10 15:25:56 - P@1000: 0.0004\n",
      "2024-03-10 15:25:56 - Load pretrained SentenceTransformer: output/tsdae-model/epoch-7-steps-375\n",
      "2024-03-10 15:25:56 - Use pytorch device_name: mps\n",
      "2024-03-10 15:25:56 - Encoding Queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:25:58 - Sorting Corpus by document length (Longest first)...\n",
      "2024-03-10 15:25:58 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2024-03-10 15:25:58 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2024-03-10 15:25:58 - Encoding Batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 648/648 [00:55<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:26:56 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]\n",
      "2024-03-10 15:26:56 - \n",
      "\n",
      "2024-03-10 15:26:56 - NDCG@1: 0.0167\n",
      "2024-03-10 15:26:56 - NDCG@3: 0.0230\n",
      "2024-03-10 15:26:56 - NDCG@5: 0.0255\n",
      "2024-03-10 15:26:56 - NDCG@10: 0.0415\n",
      "2024-03-10 15:26:56 - NDCG@100: 0.0838\n",
      "2024-03-10 15:26:56 - NDCG@1000: 0.1526\n",
      "2024-03-10 15:26:56 - \n",
      "\n",
      "2024-03-10 15:26:56 - MAP@1: 0.0167\n",
      "2024-03-10 15:26:56 - MAP@3: 0.0217\n",
      "2024-03-10 15:26:56 - MAP@5: 0.0230\n",
      "2024-03-10 15:26:56 - MAP@10: 0.0291\n",
      "2024-03-10 15:26:56 - MAP@100: 0.0359\n",
      "2024-03-10 15:26:56 - MAP@1000: 0.0382\n",
      "2024-03-10 15:26:56 - \n",
      "\n",
      "2024-03-10 15:26:56 - Recall@1: 0.0167\n",
      "2024-03-10 15:26:56 - Recall@3: 0.0267\n",
      "2024-03-10 15:26:56 - Recall@5: 0.0333\n",
      "2024-03-10 15:26:56 - Recall@10: 0.0826\n",
      "2024-03-10 15:26:56 - Recall@100: 0.2983\n",
      "2024-03-10 15:26:56 - Recall@1000: 0.8473\n",
      "2024-03-10 15:26:56 - \n",
      "\n",
      "2024-03-10 15:26:56 - P@1: 0.0167\n",
      "2024-03-10 15:26:56 - P@3: 0.0089\n",
      "2024-03-10 15:26:56 - P@5: 0.0067\n",
      "2024-03-10 15:26:56 - P@10: 0.0093\n",
      "2024-03-10 15:26:56 - P@100: 0.0033\n",
      "2024-03-10 15:26:56 - P@1000: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval import models\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "\n",
    "#### Dense Retrieval using SBERT (Sentence-BERT) ####\n",
    "#### Provide any pretrained sentence-transformers model\n",
    "#### The model was fine-tuned using cosine-similarity.\n",
    "#### Complete list - https://www.sbert.net/docs/pretrained_models.html\n",
    "l=[]\n",
    "l_index=[]\n",
    "for model_name in os.listdir(\"./output/tsdae-model\"):\n",
    "    model = DRES(models.SentenceBERT(\"output/tsdae-model/\"+model_name), batch_size=8)\n",
    "    retriever = EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "    #### Retrieve dense results (format of results is identical to qrels)\n",
    "    results = retriever.retrieve(test_corpus, test_queries)\n",
    "\n",
    "\n",
    "    logging.info(\"Retriever evaluation for k in: {}\".format(retriever.k_values))\n",
    "\n",
    "    ndcg, _map, recall, precision = retriever.evaluate(test_qrels, results, retriever.k_values,ignore_identical_ids=False)\n",
    "    ndcg.update(_map)\n",
    "    ndcg.update(recall)\n",
    "    ndcg.update(precision)\n",
    "    l_index.append(model_name)\n",
    "    l.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>NDCG@100</th>\n",
       "      <th>NDCG@1000</th>\n",
       "      <th>MAP@1</th>\n",
       "      <th>MAP@3</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>...</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Recall@100</th>\n",
       "      <th>Recall@1000</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>P@100</th>\n",
       "      <th>P@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch-12-steps-375</th>\n",
       "      <td>0.03667</td>\n",
       "      <td>0.06550</td>\n",
       "      <td>0.07855</td>\n",
       "      <td>0.09680</td>\n",
       "      <td>0.17077</td>\n",
       "      <td>0.21996</td>\n",
       "      <td>0.03667</td>\n",
       "      <td>0.05778</td>\n",
       "      <td>0.06499</td>\n",
       "      <td>0.07211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11556</td>\n",
       "      <td>0.17233</td>\n",
       "      <td>0.54311</td>\n",
       "      <td>0.93300</td>\n",
       "      <td>0.03667</td>\n",
       "      <td>0.03111</td>\n",
       "      <td>0.02600</td>\n",
       "      <td>0.01967</td>\n",
       "      <td>0.00623</td>\n",
       "      <td>0.00105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-11-steps-375</th>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.04425</td>\n",
       "      <td>0.05710</td>\n",
       "      <td>0.07424</td>\n",
       "      <td>0.13555</td>\n",
       "      <td>0.19423</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.03944</td>\n",
       "      <td>0.04625</td>\n",
       "      <td>0.05312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08639</td>\n",
       "      <td>0.13956</td>\n",
       "      <td>0.44978</td>\n",
       "      <td>0.91567</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.01933</td>\n",
       "      <td>0.01567</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.00103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-10-steps-375</th>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.04513</td>\n",
       "      <td>0.05740</td>\n",
       "      <td>0.07347</td>\n",
       "      <td>0.13412</td>\n",
       "      <td>0.19219</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.04056</td>\n",
       "      <td>0.04735</td>\n",
       "      <td>0.05390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08289</td>\n",
       "      <td>0.13289</td>\n",
       "      <td>0.43811</td>\n",
       "      <td>0.89633</td>\n",
       "      <td>0.02667</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.00510</td>\n",
       "      <td>0.00102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-9-steps-375</th>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02421</td>\n",
       "      <td>0.03517</td>\n",
       "      <td>0.05226</td>\n",
       "      <td>0.10325</td>\n",
       "      <td>0.16877</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02222</td>\n",
       "      <td>0.02810</td>\n",
       "      <td>0.03509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05583</td>\n",
       "      <td>0.10706</td>\n",
       "      <td>0.36606</td>\n",
       "      <td>0.88567</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.00100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-8-steps-375</th>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02298</td>\n",
       "      <td>0.03425</td>\n",
       "      <td>0.04923</td>\n",
       "      <td>0.09790</td>\n",
       "      <td>0.16222</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02167</td>\n",
       "      <td>0.02743</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05361</td>\n",
       "      <td>0.10039</td>\n",
       "      <td>0.35356</td>\n",
       "      <td>0.86733</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.00889</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.01133</td>\n",
       "      <td>0.00393</td>\n",
       "      <td>0.00098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-7-steps-375</th>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02298</td>\n",
       "      <td>0.02555</td>\n",
       "      <td>0.04152</td>\n",
       "      <td>0.08380</td>\n",
       "      <td>0.15256</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.02167</td>\n",
       "      <td>0.02300</td>\n",
       "      <td>0.02912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>0.29828</td>\n",
       "      <td>0.84733</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.00889</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00933</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>0.00096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-6-steps-375</th>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.02175</td>\n",
       "      <td>0.02347</td>\n",
       "      <td>0.03917</td>\n",
       "      <td>0.08376</td>\n",
       "      <td>0.14769</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.02724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03067</td>\n",
       "      <td>0.07844</td>\n",
       "      <td>0.30300</td>\n",
       "      <td>0.81567</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.00889</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00867</td>\n",
       "      <td>0.00337</td>\n",
       "      <td>0.00093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-5-steps-375</th>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.01964</td>\n",
       "      <td>0.02281</td>\n",
       "      <td>0.03180</td>\n",
       "      <td>0.07503</td>\n",
       "      <td>0.13839</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>0.02345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03067</td>\n",
       "      <td>0.05900</td>\n",
       "      <td>0.27383</td>\n",
       "      <td>0.78522</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00633</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>0.00089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-4-steps-375</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01421</td>\n",
       "      <td>0.01693</td>\n",
       "      <td>0.02027</td>\n",
       "      <td>0.05438</td>\n",
       "      <td>0.12033</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.01483</td>\n",
       "      <td>0.01619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02333</td>\n",
       "      <td>0.03233</td>\n",
       "      <td>0.19856</td>\n",
       "      <td>0.72289</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>0.00467</td>\n",
       "      <td>0.00367</td>\n",
       "      <td>0.00220</td>\n",
       "      <td>0.00083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-3-steps-375</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00773</td>\n",
       "      <td>0.00969</td>\n",
       "      <td>0.03550</td>\n",
       "      <td>0.10034</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.00665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.14789</td>\n",
       "      <td>0.67122</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00267</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00163</td>\n",
       "      <td>0.00077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-2-steps-375</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00462</td>\n",
       "      <td>0.00670</td>\n",
       "      <td>0.02651</td>\n",
       "      <td>0.09038</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.12011</td>\n",
       "      <td>0.64928</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-1-steps-375</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.01892</td>\n",
       "      <td>0.07680</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.08678</td>\n",
       "      <td>0.56678</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-13-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.01489</td>\n",
       "      <td>0.06347</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-14-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00767</td>\n",
       "      <td>0.01351</td>\n",
       "      <td>0.06278</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.03944</td>\n",
       "      <td>0.45261</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-18-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.01259</td>\n",
       "      <td>0.06235</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.03278</td>\n",
       "      <td>0.45033</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-17-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00886</td>\n",
       "      <td>0.01208</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.03167</td>\n",
       "      <td>0.45472</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-16-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01311</td>\n",
       "      <td>0.06092</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.03833</td>\n",
       "      <td>0.43433</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-15-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.01228</td>\n",
       "      <td>0.06089</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.03278</td>\n",
       "      <td>0.44328</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-8-steps-51</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00644</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00956</td>\n",
       "      <td>0.05947</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.44361</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-9-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.01138</td>\n",
       "      <td>0.05917</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.02333</td>\n",
       "      <td>0.42761</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-11-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.00877</td>\n",
       "      <td>0.00973</td>\n",
       "      <td>0.01321</td>\n",
       "      <td>0.05912</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.00867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01333</td>\n",
       "      <td>0.03167</td>\n",
       "      <td>0.41417</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-19-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>0.01405</td>\n",
       "      <td>0.05822</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.42206</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.00048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-10-steps-51</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01283</td>\n",
       "      <td>0.05636</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.38850</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-12-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.01228</td>\n",
       "      <td>0.05535</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.03167</td>\n",
       "      <td>0.39278</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-7-steps-51</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00834</td>\n",
       "      <td>0.05403</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.02167</td>\n",
       "      <td>0.40950</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-6-steps-51</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00644</td>\n",
       "      <td>0.00971</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.02833</td>\n",
       "      <td>0.38944</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.00045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-4-steps-51</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00210</td>\n",
       "      <td>0.00329</td>\n",
       "      <td>0.00599</td>\n",
       "      <td>0.05040</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>0.39189</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-5-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00928</td>\n",
       "      <td>0.04984</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.02167</td>\n",
       "      <td>0.37011</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.00042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-0-steps-375</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00670</td>\n",
       "      <td>0.04857</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.02233</td>\n",
       "      <td>0.38611</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-3-steps-51</th>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00969</td>\n",
       "      <td>0.04737</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.35472</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-2-steps-51</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00105</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.03884</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.01833</td>\n",
       "      <td>0.32278</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-1-steps-51</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.00329</td>\n",
       "      <td>0.03236</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.26878</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch-0-steps-51</th>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>0.00471</td>\n",
       "      <td>0.02679</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00667</td>\n",
       "      <td>0.00833</td>\n",
       "      <td>0.20522</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NDCG@1   NDCG@3   NDCG@5  NDCG@10  NDCG@100  NDCG@1000  \\\n",
       "epoch-12-steps-375  0.03667  0.06550  0.07855  0.09680   0.17077    0.21996   \n",
       "epoch-11-steps-375  0.02667  0.04425  0.05710  0.07424   0.13555    0.19423   \n",
       "epoch-10-steps-375  0.02667  0.04513  0.05740  0.07347   0.13412    0.19219   \n",
       "epoch-9-steps-375   0.01667  0.02421  0.03517  0.05226   0.10325    0.16877   \n",
       "epoch-8-steps-375   0.01667  0.02298  0.03425  0.04923   0.09790    0.16222   \n",
       "epoch-7-steps-375   0.01667  0.02298  0.02555  0.04152   0.08380    0.15256   \n",
       "epoch-6-steps-375   0.01333  0.02175  0.02347  0.03917   0.08376    0.14769   \n",
       "epoch-5-steps-375   0.01333  0.01964  0.02281  0.03180   0.07503    0.13839   \n",
       "epoch-4-steps-375   0.01000  0.01421  0.01693  0.02027   0.05438    0.12033   \n",
       "epoch-3-steps-375   0.00333  0.00500  0.00773  0.00969   0.03550    0.10034   \n",
       "epoch-2-steps-375   0.00333  0.00333  0.00462  0.00670   0.02651    0.09038   \n",
       "epoch-1-steps-375   0.00333  0.00333  0.00333  0.00333   0.01892    0.07680   \n",
       "epoch-13-steps-51   0.00667  0.00667  0.00810  0.00810   0.01489    0.06347   \n",
       "epoch-14-steps-51   0.00667  0.00667  0.00667  0.00767   0.01351    0.06278   \n",
       "epoch-18-steps-51   0.00667  0.00833  0.00833  0.00833   0.01259    0.06235   \n",
       "epoch-17-steps-51   0.00667  0.00667  0.00667  0.00886   0.01208    0.06189   \n",
       "epoch-16-steps-51   0.00667  0.00667  0.00667  0.00667   0.01311    0.06092   \n",
       "epoch-15-steps-51   0.00667  0.00667  0.00810  0.00810   0.01228    0.06089   \n",
       "epoch-8-steps-51    0.00333  0.00500  0.00644  0.00740   0.00956    0.05947   \n",
       "epoch-9-steps-51    0.00667  0.00877  0.00877  0.00877   0.01138    0.05917   \n",
       "epoch-11-steps-51   0.00667  0.00877  0.00877  0.00973   0.01321    0.05912   \n",
       "epoch-19-steps-51   0.00667  0.00667  0.00667  0.00778   0.01405    0.05822   \n",
       "epoch-10-steps-51   0.01000  0.01000  0.01000  0.01000   0.01283    0.05636   \n",
       "epoch-12-steps-51   0.00667  0.00667  0.00810  0.00810   0.01228    0.05535   \n",
       "epoch-7-steps-51    0.00333  0.00544  0.00544  0.00544   0.00834    0.05403   \n",
       "epoch-6-steps-51    0.00333  0.00544  0.00544  0.00644   0.00971    0.05233   \n",
       "epoch-4-steps-51    0.00000  0.00210  0.00210  0.00329   0.00599    0.05040   \n",
       "epoch-5-steps-51    0.00667  0.00667  0.00667  0.00667   0.00928    0.04984   \n",
       "epoch-0-steps-375   0.00333  0.00333  0.00333  0.00333   0.00670    0.04857   \n",
       "epoch-3-steps-51    0.00667  0.00667  0.00667  0.00667   0.00969    0.04737   \n",
       "epoch-2-steps-51    0.00000  0.00000  0.00000  0.00105   0.00391    0.03884   \n",
       "epoch-1-steps-51    0.00000  0.00000  0.00000  0.00100   0.00329    0.03236   \n",
       "epoch-0-steps-51    0.00333  0.00333  0.00333  0.00438   0.00471    0.02679   \n",
       "\n",
       "                      MAP@1    MAP@3    MAP@5   MAP@10  ...  Recall@5  \\\n",
       "epoch-12-steps-375  0.03667  0.05778  0.06499  0.07211  ...   0.11556   \n",
       "epoch-11-steps-375  0.02667  0.03944  0.04625  0.05312  ...   0.08639   \n",
       "epoch-10-steps-375  0.02667  0.04056  0.04735  0.05390  ...   0.08289   \n",
       "epoch-9-steps-375   0.01667  0.02222  0.02810  0.03509  ...   0.05583   \n",
       "epoch-8-steps-375   0.01667  0.02167  0.02743  0.03333  ...   0.05361   \n",
       "epoch-7-steps-375   0.01667  0.02167  0.02300  0.02912  ...   0.03333   \n",
       "epoch-6-steps-375   0.01333  0.02000  0.02080  0.02724  ...   0.03067   \n",
       "epoch-5-steps-375   0.01333  0.01833  0.01997  0.02345  ...   0.03067   \n",
       "epoch-4-steps-375   0.01000  0.01333  0.01483  0.01619  ...   0.02333   \n",
       "epoch-3-steps-375   0.00333  0.00444  0.00594  0.00665  ...   0.01333   \n",
       "epoch-2-steps-375   0.00333  0.00333  0.00400  0.00481  ...   0.00667   \n",
       "epoch-1-steps-375   0.00333  0.00333  0.00333  0.00333  ...   0.00333   \n",
       "epoch-13-steps-51   0.00667  0.00667  0.00750  0.00750  ...   0.01000   \n",
       "epoch-14-steps-51   0.00667  0.00667  0.00667  0.00704  ...   0.00667   \n",
       "epoch-18-steps-51   0.00667  0.00778  0.00778  0.00778  ...   0.01000   \n",
       "epoch-17-steps-51   0.00667  0.00667  0.00667  0.00759  ...   0.00667   \n",
       "epoch-16-steps-51   0.00667  0.00667  0.00667  0.00667  ...   0.00667   \n",
       "epoch-15-steps-51   0.00667  0.00667  0.00750  0.00750  ...   0.01000   \n",
       "epoch-8-steps-51    0.00333  0.00444  0.00528  0.00561  ...   0.01000   \n",
       "epoch-9-steps-51    0.00667  0.00833  0.00833  0.00833  ...   0.01000   \n",
       "epoch-11-steps-51   0.00667  0.00833  0.00833  0.00867  ...   0.01000   \n",
       "epoch-19-steps-51   0.00667  0.00667  0.00667  0.00714  ...   0.00667   \n",
       "epoch-10-steps-51   0.01000  0.01000  0.01000  0.01000  ...   0.01000   \n",
       "epoch-12-steps-51   0.00667  0.00667  0.00750  0.00750  ...   0.01000   \n",
       "epoch-7-steps-51    0.00333  0.00500  0.00500  0.00500  ...   0.00667   \n",
       "epoch-6-steps-51    0.00333  0.00500  0.00500  0.00537  ...   0.00667   \n",
       "epoch-4-steps-51    0.00000  0.00167  0.00167  0.00222  ...   0.00333   \n",
       "epoch-5-steps-51    0.00667  0.00667  0.00667  0.00667  ...   0.00667   \n",
       "epoch-0-steps-375   0.00333  0.00333  0.00333  0.00333  ...   0.00333   \n",
       "epoch-3-steps-51    0.00667  0.00667  0.00667  0.00667  ...   0.00667   \n",
       "epoch-2-steps-51    0.00000  0.00000  0.00000  0.00042  ...   0.00000   \n",
       "epoch-1-steps-51    0.00000  0.00000  0.00000  0.00037  ...   0.00000   \n",
       "epoch-0-steps-51    0.00333  0.00333  0.00333  0.00375  ...   0.00333   \n",
       "\n",
       "                    Recall@10  Recall@100  Recall@1000      P@1      P@3  \\\n",
       "epoch-12-steps-375    0.17233     0.54311      0.93300  0.03667  0.03111   \n",
       "epoch-11-steps-375    0.13956     0.44978      0.91567  0.02667  0.02000   \n",
       "epoch-10-steps-375    0.13289     0.43811      0.89633  0.02667  0.02000   \n",
       "epoch-9-steps-375     0.10706     0.36606      0.88567  0.01667  0.01000   \n",
       "epoch-8-steps-375     0.10039     0.35356      0.86733  0.01667  0.00889   \n",
       "epoch-7-steps-375     0.08261     0.29828      0.84733  0.01667  0.00889   \n",
       "epoch-6-steps-375     0.07844     0.30300      0.81567  0.01333  0.00889   \n",
       "epoch-5-steps-375     0.05900     0.27383      0.78522  0.01333  0.00778   \n",
       "epoch-4-steps-375     0.03233     0.19856      0.72289  0.01000  0.00556   \n",
       "epoch-3-steps-375     0.02000     0.14789      0.67122  0.00333  0.00222   \n",
       "epoch-2-steps-375     0.01333     0.12011      0.64928  0.00333  0.00111   \n",
       "epoch-1-steps-375     0.00333     0.08678      0.56678  0.00333  0.00111   \n",
       "epoch-13-steps-51     0.01000     0.04500      0.45356  0.00667  0.00222   \n",
       "epoch-14-steps-51     0.01000     0.03944      0.45261  0.00667  0.00222   \n",
       "epoch-18-steps-51     0.01000     0.03278      0.45033  0.00667  0.00333   \n",
       "epoch-17-steps-51     0.01333     0.03167      0.45472  0.00667  0.00222   \n",
       "epoch-16-steps-51     0.00667     0.03833      0.43433  0.00667  0.00222   \n",
       "epoch-15-steps-51     0.01000     0.03278      0.44328  0.00667  0.00222   \n",
       "epoch-8-steps-51      0.01333     0.02500      0.44361  0.00333  0.00222   \n",
       "epoch-9-steps-51      0.01000     0.02333      0.42761  0.00667  0.00333   \n",
       "epoch-11-steps-51     0.01333     0.03167      0.41417  0.00667  0.00333   \n",
       "epoch-19-steps-51     0.01000     0.04500      0.42206  0.00667  0.00222   \n",
       "epoch-10-steps-51     0.01000     0.02500      0.38850  0.01000  0.00333   \n",
       "epoch-12-steps-51     0.01000     0.03167      0.39278  0.00667  0.00222   \n",
       "epoch-7-steps-51      0.00667     0.02167      0.40950  0.00333  0.00222   \n",
       "epoch-6-steps-51      0.01000     0.02833      0.38944  0.00333  0.00222   \n",
       "epoch-4-steps-51      0.00667     0.01833      0.39189  0.00000  0.00111   \n",
       "epoch-5-steps-51      0.00667     0.02167      0.37011  0.00667  0.00222   \n",
       "epoch-0-steps-375     0.00333     0.02233      0.38611  0.00333  0.00111   \n",
       "epoch-3-steps-51      0.00667     0.02500      0.35472  0.00667  0.00222   \n",
       "epoch-2-steps-51      0.00333     0.01833      0.32278  0.00000  0.00000   \n",
       "epoch-1-steps-51      0.00333     0.01500      0.26878  0.00000  0.00000   \n",
       "epoch-0-steps-51      0.00667     0.00833      0.20522  0.00333  0.00111   \n",
       "\n",
       "                        P@5     P@10    P@100   P@1000  \n",
       "epoch-12-steps-375  0.02600  0.01967  0.00623  0.00105  \n",
       "epoch-11-steps-375  0.01933  0.01567  0.00517  0.00103  \n",
       "epoch-10-steps-375  0.02000  0.01500  0.00510  0.00102  \n",
       "epoch-9-steps-375   0.01200  0.01200  0.00417  0.00100  \n",
       "epoch-8-steps-375   0.01200  0.01133  0.00393  0.00098  \n",
       "epoch-7-steps-375   0.00667  0.00933  0.00330  0.00096  \n",
       "epoch-6-steps-375   0.00667  0.00867  0.00337  0.00093  \n",
       "epoch-5-steps-375   0.00667  0.00633  0.00303  0.00089  \n",
       "epoch-4-steps-375   0.00467  0.00367  0.00220  0.00083  \n",
       "epoch-3-steps-375   0.00267  0.00200  0.00163  0.00077  \n",
       "epoch-2-steps-375   0.00133  0.00133  0.00133  0.00074  \n",
       "epoch-1-steps-375   0.00067  0.00033  0.00093  0.00063  \n",
       "epoch-13-steps-51   0.00200  0.00100  0.00047  0.00052  \n",
       "epoch-14-steps-51   0.00133  0.00100  0.00043  0.00051  \n",
       "epoch-18-steps-51   0.00200  0.00100  0.00037  0.00051  \n",
       "epoch-17-steps-51   0.00133  0.00133  0.00033  0.00051  \n",
       "epoch-16-steps-51   0.00133  0.00067  0.00047  0.00050  \n",
       "epoch-15-steps-51   0.00200  0.00100  0.00037  0.00051  \n",
       "epoch-8-steps-51    0.00200  0.00133  0.00027  0.00051  \n",
       "epoch-9-steps-51    0.00200  0.00100  0.00027  0.00049  \n",
       "epoch-11-steps-51   0.00200  0.00133  0.00033  0.00047  \n",
       "epoch-19-steps-51   0.00133  0.00100  0.00047  0.00048  \n",
       "epoch-10-steps-51   0.00200  0.00100  0.00027  0.00043  \n",
       "epoch-12-steps-51   0.00200  0.00100  0.00033  0.00044  \n",
       "epoch-7-steps-51    0.00133  0.00067  0.00023  0.00046  \n",
       "epoch-6-steps-51    0.00133  0.00100  0.00030  0.00045  \n",
       "epoch-4-steps-51    0.00067  0.00067  0.00020  0.00045  \n",
       "epoch-5-steps-51    0.00133  0.00067  0.00023  0.00042  \n",
       "epoch-0-steps-375   0.00067  0.00033  0.00027  0.00043  \n",
       "epoch-3-steps-51    0.00133  0.00067  0.00027  0.00040  \n",
       "epoch-2-steps-51    0.00000  0.00033  0.00020  0.00036  \n",
       "epoch-1-steps-51    0.00000  0.00033  0.00017  0.00030  \n",
       "epoch-0-steps-51    0.00067  0.00067  0.00010  0.00022  \n",
       "\n",
       "[33 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(l, index=l_index).sort_values('NDCG@1000', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
