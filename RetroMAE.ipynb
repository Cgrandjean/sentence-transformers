{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/cgrdj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models as beir_models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from typing import List\n",
    "from sentence_transformers.readers import InputExample\n",
    "import numpy as np\n",
    "from transformers.utils.import_utils import is_nltk_available, NLTK_IMPORT_ERROR\n",
    "from nltk import word_tokenize, TreebankWordDetokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from torch import nn, Tensor\n",
    "from typing import Iterable, Dict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, PreTrainedModel,AutoModel\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,do_lower_case=False,clean_up_tokenization_spaces=False,clean_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /home/cgrdj/Documents/code/repos/sentence-transformers/datasets/scifact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5183 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 85672.59it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))\n",
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"train\") # or split = \"train\" or \"dev\"\n",
    "unsupervised_train_data =  list(queries.values())#+[data['title']+' \\n '+data['text'] for data in list(corpus.values())]\n",
    "random.Random(0).shuffle(unsupervised_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaskedAutoEncoderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The DenoisingAutoEncoderDataset returns InputExamples in the format: texts=[noise_fn(sentence), sentence]\n",
    "    It is used in combination with the DenoisingAutoEncoderLoss: Here, a decoder tries to re-construct the\n",
    "    sentence without noise.\n",
    "\n",
    "    :param sentences: A list of sentences\n",
    "    :param noise_fn: A noise function: Given a string, it returns a string with noise, e.g. deleted words\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences: List[str],tokenizer ):\n",
    "        if not is_nltk_available():\n",
    "            raise ImportError(NLTK_IMPORT_ERROR.format(self.__class__.__name__))\n",
    "\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer=tokenizer\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sent = self.sentences[item]\n",
    "        return InputExample(texts=[self.noisen(sent,MASK_ratio=0.15), self.noisen(sent,MASK_ratio=0.4),sent])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    # Masking noise.\n",
    "    def noisen(self,text, MASK_ratio=0.15):\n",
    "        mask_id=self.tokenizer.mask_token_id\n",
    "        words= text.split()#word_tokenize(text)\n",
    "        # Apply the masking logic to each word and rejoin the sentence\n",
    "        splitted_tokens = self.tokenizer.batch_encode_plus(words,return_attention_mask=False,return_token_type_ids=False,add_special_tokens=False)['input_ids']#encode each tokens in each\n",
    "        masked_tokens =[[ mask_id if np.random.rand() < MASK_ratio else tok_id for tok_id in token]  for token in splitted_tokens]\n",
    "        masked_sentence=' '.join([self.tokenizer.decode(masked_token).replace(\" \",'') for masked_token in masked_tokens])\n",
    "        return masked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=512)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \"cls\")\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaskedAutoEncoderLoss(nn.Module):\n",
    "    def __init__(self, model: SentenceTransformer, decoder_name_or_path: str = None):\n",
    "        \"\"\"\n",
    "        This loss expects as input a pairs of damaged sentences and the corresponding original ones.\n",
    "        During training, the decoder reconstructs the original sentences from the encoded sentence embeddings.\n",
    "        Here the argument 'decoder_name_or_path' indicates the pretrained model (supported by Hugging Face) to be used as the decoder.\n",
    "        Since decoding process is included, here the decoder should have a class called XXXLMHead (in the context of Hugging Face's Transformers).\n",
    "        The 'tie_encoder_decoder' flag indicates whether to tie the trainable parameters of encoder and decoder,\n",
    "        which is shown beneficial to model performance while limiting the amount of required memory.\n",
    "        Only when the encoder and decoder are from the same architecture, can the flag 'tie_encoder_decoder' work.\n",
    "\n",
    "        The data generation process (i.e. the 'damaging' process) has already been implemented in ``DenoisingAutoEncoderDataset``,\n",
    "        allowing you to only provide regular sentences.\n",
    "\n",
    "        :param model: SentenceTransformer model\n",
    "        :param decoder_name_or_path: Model name or path for initializing a decoder (compatible with Huggingface's Transformers)\n",
    "        :param tie_encoder_decoder: whether to tie the trainable parameters of encoder and decoder\n",
    "\n",
    "        References:\n",
    "            * TSDAE paper: https://arxiv.org/pdf/2104.06979.pdf\n",
    "            * `Unsupervised Learning > TSDAE <../../examples/unsupervised_learning/TSDAE/README.html>`_\n",
    "\n",
    "        Requirements:\n",
    "            1. The decoder should have a class called XXXLMHead (in the context of Hugging Face's Transformers)\n",
    "            2. Should use a large corpus\n",
    "\n",
    "        Inputs:\n",
    "            +------------------------------------------------------+--------+\n",
    "            | Texts                                                | Labels |\n",
    "            +======================================================+========+\n",
    "            | (damaged\\_sentence, original\\_sentence) pairs        | none   |\n",
    "            +------------------------------------------------------+--------+\n",
    "            | sentence fed through ``DenoisingAutoEncoderDataset`` | none   |\n",
    "            +------------------------------------------------------+--------+\n",
    "\n",
    "        Example:\n",
    "            ::\n",
    "\n",
    "                from sentence_transformers import SentenceTransformer, losses\n",
    "                from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n",
    "                from torch.utils.data import DataLoader\n",
    "\n",
    "                model_name = \"bert-base-cased\"\n",
    "                model = SentenceTransformer(model_name)\n",
    "                train_sentences = [\n",
    "                    \"First training sentence\", \"Second training sentence\", \"Third training sentence\", \"Fourth training sentence\",\n",
    "                ]\n",
    "                batch_size = 2\n",
    "                train_dataset = DenoisingAutoEncoderDataset(train_sentences)\n",
    "                train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "                train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "                    model, decoder_name_or_path=model_name, tie_encoder_decoder=True\n",
    "                )\n",
    "                model.fit(\n",
    "                    train_objectives=[(train_dataloader, train_loss)],\n",
    "                    epochs=10,\n",
    "                )\n",
    "        \"\"\"\n",
    "        super(MaskedAutoEncoderLoss, self).__init__()\n",
    "        self.encoder = model  # This will be the final model used during the inference time.\n",
    "        self.tokenizer_encoder = model.tokenizer\n",
    "\n",
    "        name_or_path = model[0].auto_model.config._name_or_path\n",
    "\n",
    "        self.tokenizer_decoder = AutoTokenizer.from_pretrained(name_or_path)\n",
    "\n",
    "        decoder_config = AutoConfig.from_pretrained(name_or_path)\n",
    "        decoder_config.is_decoder = True\n",
    "        decoder_config.add_cross_attention = True\n",
    "        decoder_config.num_hidden_layers=1\n",
    "        kwargs_decoder = {\"config\": decoder_config}\n",
    "        try:\n",
    "            self.decoder = AutoModelForCausalLM.from_pretrained(name_or_path, **kwargs_decoder)\n",
    "        except ValueError as e:\n",
    "            logger.error(\n",
    "                f'Model name or path \"{name_or_path}\" does not support being as a decoder. Please make sure the decoder model has an \"XXXLMHead\" class.'\n",
    "            )\n",
    "            raise e\n",
    "        if self.tokenizer_decoder.pad_token is None:\n",
    "            # Needed by GPT-2, etc.\n",
    "            self.tokenizer_decoder.pad_token = self.tokenizer_decoder.eos_token\n",
    "            self.decoder.config.pad_token_id = self.decoder.config.eos_token_id\n",
    "\n",
    "        if len(AutoTokenizer.from_pretrained(name_or_path)) != len(self.tokenizer_encoder):\n",
    "            logger.warning(\n",
    "                \"WARNING: The vocabulary of the encoder has been changed. One might need to change the decoder vocabulary, too.\"\n",
    "            )\n",
    "\n",
    "    def forward(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor):\n",
    "        source_features, target_features= tuple(sentence_features)\n",
    "        reps = self.encoder(source_features)[\"sentence_embedding\"]  # (bsz, hdim)\n",
    "        # print(source_features)\n",
    "        # Prepare input and output\n",
    "        target_length = target_features[\"input_ids\"].shape[1]\n",
    "        decoder_input_ids = target_features[\"input_ids\"].clone()[:, : target_length - 1]\n",
    "        print( target_features[\"input_ids\"],decoder_input_ids)\n",
    "        # print(decoder_input_ids.shape)\n",
    "        label_ids = target_features[\"input_ids\"][:, 1:]\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            inputs_embeds=None,\n",
    "            attention_mask=None,\n",
    "            encoder_hidden_states=reps[:, None],  # (bsz, hdim) -> (bsz, 1, hdim)\n",
    "            encoder_attention_mask=source_features[\"attention_mask\"][:, 0:1],\n",
    "            labels=None,\n",
    "            return_dict=None,\n",
    "            use_cache=False,\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        lm_logits = decoder_outputs[0]\n",
    "        ce_loss_fct = nn.CrossEntropyLoss(ignore_index=self.tokenizer_decoder.pad_token_id)\n",
    "        loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), label_ids.reshape(-1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def forward_(self, sentence_features: Iterable[Dict[str, Tensor]], labels: Tensor):\n",
    "        encoder_inputs,decoder_inputs , target_features = tuple(sentence_features)\n",
    "        reps = self.encoder(encoder_inputs)[\"sentence_embedding\"]  # (bsz, hdim)\n",
    "\n",
    "        # Prepare input and output\n",
    "        target_length = target_features[\"input_ids\"].shape[1]\n",
    "        decoder_input_ids = target_features[\"input_ids\"].clone()[:, : target_length - 1]\n",
    "        label_ids = target_features[\"input_ids\"][:, 1:]\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            inputs_embeds=None,\n",
    "            attention_mask=None,\n",
    "            encoder_hidden_states=reps[:, None],  # (bsz, hdim) -> (bsz, 1, hdim)\n",
    "            encoder_attention_mask=encoder_inputs[\"attention_mask\"][:, 0:1],\n",
    "            labels=None,\n",
    "            return_dict=None,\n",
    "            use_cache=False,\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        lm_logits = decoder_outputs[0]\n",
    "        ce_loss_fct = nn.CrossEntropyLoss(ignore_index=self.tokenizer_decoder.pad_token_id)\n",
    "        loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), label_ids.reshape(-1))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoder_config = AutoConfig.from_pretrained(model_name)\n",
    "decoder_config.is_decoder = True\n",
    "decoder_config.add_cross_attention = True\n",
    "decoder_config.num_hidden_layers=1\n",
    "kwargs_decoder = {\"config\": decoder_config}\n",
    "decoder = AutoModelForCausalLM.from_pretrained(model_name, **kwargs_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=['I m going to','We provided with']\n",
    "decoder_input_ids=model.tokenizer(text,padding=True,truncation=True)\n",
    "reps=model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 312])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 1049, 2183, 2000],\n",
       "        [ 101, 2057, 3024, 2007,  102]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(decoder_input_ids['input_ids']).clone()[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder(\n",
    "    input_ids=torch.tensor(decoder_input_ids['input_ids']).clone()[:, :5],\n",
    "    inputs_embeds=None,\n",
    "    attention_mask=None,\n",
    "    encoder_hidden_states=torch.tensor(reps).unsqueeze(1),  # (bsz, hdim) -> (bsz, 1, hdim)\n",
    "    # encoder_attention_mask=[1,1],\n",
    "    labels=None,\n",
    "    return_dict=None,\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ministers if lavish enable\n",
      "needed draws losseit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "probabilities = torch.softmax(decoder_outputs.logits, dim=-1)\n",
    "\n",
    "# Choose the tokens with the highest probability\n",
    "predicted_token_ids = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "# Convert token IDs to tokens\n",
    "predicted_tokens = [model.tokenizer.decode(generated_ids, skip_special_tokens=True) for generated_ids in predicted_token_ids]\n",
    "\n",
    "# Print out the generated texts\n",
    "for text in predicted_tokens:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset=MaskedAutoEncoderDataset(unsupervised_train_data,tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "train_loss = MaskedAutoEncoderLoss(model, decoder_name_or_path=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset=datasets.DenoisingAutoEncoderDataset(unsupervised_train_data)#,tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "train_loss = MaskedAutoEncoderLoss(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] azt given with ribavirin increases anemia. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([  101, 17207,  2102,  2445,  2007, 19395, 18891,  6657,  7457,  2019,\n",
    "         17577,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] azt given with ribavirin increases anemia. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([  101, 17207,  2102,  2445,  2007, 19395, 18891,  6657,  7457,  2019,\n",
    "         17577,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 17207,  2102,  2445,  2007, 19395, 18891,  6657,  7457,  2019,\n",
      "         17577,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  1996,  4315, 13910,  8898,  1998, 15330, 13791,  1997, 18847,\n",
      "         27321,  2038,  3972, 15141,  6313,  3896,  1999, 11888, 16514,  3785,\n",
      "          1012,   102],\n",
      "        [  101, 19802,  6190,  3141, 13356,  2038, 13763,  2013,  2268,  2000,\n",
      "          2297,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3445, 19251,  1997, 12702, 21102,  3688, 16081,  2229, 11311,\n",
      "         10960,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]) tensor([[  101, 17207,  2102,  2445,  2007, 19395, 18891,  6657,  7457,  2019,\n",
      "         17577,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  1996,  4315, 13910,  8898,  1998, 15330, 13791,  1997, 18847,\n",
      "         27321,  2038,  3972, 15141,  6313,  3896,  1999, 11888, 16514,  3785,\n",
      "          1012],\n",
      "        [  101, 19802,  6190,  3141, 13356,  2038, 13763,  2013,  2268,  2000,\n",
      "          2297,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3445, 19251,  1997, 12702, 21102,  3688, 16081,  2229, 11311,\n",
      "         10960,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1996, 26236,  2615,  1011,  1016,  8985,  2003,  4050,  2004,\n",
      "         24335, 13876,  9626,  4588,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7688, 11661,  3417,  2083, 18780,  1006, 18133,  2102,  1007,\n",
      "          2003, 13567,  3141,  2000, 26957,  5657,  7865,  1006,  7939,  2615,\n",
      "          1011,  1015,  1007, 19241,  1999,  2250,  4026, 24636,  1012,   102],\n",
      "        [  101,  4125, 19440,  3686,  7457,  3891,  1997,  2310, 19731, 10024,\n",
      "          2140,  1998,  2512,  1011,  2310, 19731, 10024,  2140, 28929,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998, 22991, 16530,  5292, 24759,  9314,  8000, 28086,  8713,\n",
      "          7872,  4442,  1006,  9686,  6169,  1007,  2064,  2022,  5173,  1998,\n",
      "         19345, 20063,  1999, 25714,  1012,   102,     0,     0,     0,     0]]) tensor([[  101,  1996, 26236,  2615,  1011,  1016,  8985,  2003,  4050,  2004,\n",
      "         24335, 13876,  9626,  4588,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  7688, 11661,  3417,  2083, 18780,  1006, 18133,  2102,  1007,\n",
      "          2003, 13567,  3141,  2000, 26957,  5657,  7865,  1006,  7939,  2615,\n",
      "          1011,  1015,  1007, 19241,  1999,  2250,  4026, 24636,  1012],\n",
      "        [  101,  4125, 19440,  3686,  7457,  3891,  1997,  2310, 19731, 10024,\n",
      "          2140,  1998,  2512,  1011,  2310, 19731, 10024,  2140, 28929,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1998, 22991, 16530,  5292, 24759,  9314,  8000, 28086,  8713,\n",
      "          7872,  4442,  1006,  9686,  6169,  1007,  2064,  2022,  5173,  1998,\n",
      "         19345, 20063,  1999, 25714,  1012,   102,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1052, 12541, 13820,  9153,  7629, 16171, 20250,  1997, 24004,\n",
      "         21197,  3560, 28667,  5358, 21114,  3508,  1011, 28829,  4442,  1012,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 27312,  8606,  6022, 13416,  1996,  2193,  1997, 12201, 23851,\n",
      "          4740,  4072,  2005,  1037,  2445,  7709,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  3151,  4391,  2024, 25352,  1999,  2037, 15931,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  1996,  4304,  1997, 22330, 18715,  3170, 10769,  7682,  4442,\n",
      "          2038,  2053,  3466,  2006,  1996,  3292,  2058,  2029, 22330, 18715,\n",
      "         10586,  2552,  1012,   102]]) tensor([[  101,  1052, 12541, 13820,  9153,  7629, 16171, 20250,  1997, 24004,\n",
      "         21197,  3560, 28667,  5358, 21114,  3508,  1011, 28829,  4442,  1012,\n",
      "           102,     0,     0],\n",
      "        [  101, 27312,  8606,  6022, 13416,  1996,  2193,  1997, 12201, 23851,\n",
      "          4740,  4072,  2005,  1037,  2445,  7709,  1012,   102,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  3151,  4391,  2024, 25352,  1999,  2037, 15931,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  1996,  4304,  1997, 22330, 18715,  3170, 10769,  7682,  4442,\n",
      "          2038,  2053,  3466,  2006,  1996,  3292,  2058,  2029, 22330, 18715,\n",
      "         10586,  2552,  1012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 10210, 11663, 15422,  4360,  2377,  1037,  2350,  2535,  1999,\n",
      "          2943,  2537,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22575, 10047, 23041,  2891,  6279, 27484,  1006,  2003,  1007,\n",
      "          7242,  7457,  1996,  3382,  1997,  4456, 13356,  1999,  5022,  2007,\n",
      "         20187,  3239,  4295,  1006, 29464,  2094,  1007,   102],\n",
      "        [  101,  2012,  2560,  5594,  1003,  1997,  5022,  6086,  2000,  8249,\n",
      "          2031,  8878, 16387,  1997,  2026, 11253, 12322,  3217, 28522, 12837,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1999,  2274, 11707,  6721,  3550,  4758,  7012,  2024,\n",
      "          8944,  2220,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]) tensor([[  101, 10210, 11663, 15422,  4360,  2377,  1037,  2350,  2535,  1999,\n",
      "          2943,  2537,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 22575, 10047, 23041,  2891,  6279, 27484,  1006,  2003,  1007,\n",
      "          7242,  7457,  1996,  3382,  1997,  4456, 13356,  1999,  5022,  2007,\n",
      "         20187,  3239,  4295,  1006, 29464,  2094,  1007],\n",
      "        [  101,  2012,  2560,  5594,  1003,  1997,  5022,  6086,  2000,  8249,\n",
      "          2031,  8878, 16387,  1997,  2026, 11253, 12322,  3217, 28522, 12837,\n",
      "          1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  2028,  1999,  2274, 11707,  6721,  3550,  4758,  7012,  2024,\n",
      "          8944,  2220,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  8208,  1997,  1044,  2509,  2243,  2683,  4168,  2509,  2011,\n",
      "         14925, 14399,  2594,  3670,  1997,  2060,  1044,  2509,  2243,  2683,\n",
      "         17183, 11031, 23943,  8583, 17913, 16360,  3217, 13113,  6562,  8122,\n",
      "          1999,  8040,  3372,  7885,  1012,   102],\n",
      "        [  101, 11721,  2696,  2509, 26773,  2969,  1011, 14524,  3977,  1999,\n",
      "          5923, 24960, 19610, 10610,  6873,  2666,  4588,  7872,  4442,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  6583,  2278,  4078,  2696, 14454, 10057,  2053,  2000,  3623,\n",
      "          1996,  3466,  1997,  5688,  6074,  2006, 25125,  4972,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2753,  1003,  1997,  5022,  6086,  2000,  8249,  2031,  8878,\n",
      "         16387,  1997,  2033,  5054, 11714,  9067,  7872,  4442,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]) tensor([[  101,  8208,  1997,  1044,  2509,  2243,  2683,  4168,  2509,  2011,\n",
      "         14925, 14399,  2594,  3670,  1997,  2060,  1044,  2509,  2243,  2683,\n",
      "         17183, 11031, 23943,  8583, 17913, 16360,  3217, 13113,  6562,  8122,\n",
      "          1999,  8040,  3372,  7885,  1012],\n",
      "        [  101, 11721,  2696,  2509, 26773,  2969,  1011, 14524,  3977,  1999,\n",
      "          5923, 24960, 19610, 10610,  6873,  2666,  4588,  7872,  4442,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  6583,  2278,  4078,  2696, 14454, 10057,  2053,  2000,  3623,\n",
      "          1996,  3466,  1997,  5688,  6074,  2006, 25125,  4972,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2753,  1003,  1997,  5022,  6086,  2000,  8249,  2031,  8878,\n",
      "         16387,  1997,  2033,  5054, 11714,  9067,  7872,  4442,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 24216,  2015,  2090,  7435,  1998,  5022,  2064,  2599,  2000,\n",
      "          2512,  1011, 29235,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4013, 15509, 18514,  3977,  1997,  4013,  6914, 27287,\n",
      "          2003, 12222,  3526,  1011,  8392,  2135,  1012,   102,     0,     0],\n",
      "        [  101,  3949,  2007,  1037,  5250,  2315,  1042,  2078,  9239,  2015,\n",
      "         19723, 24454,  8082,  7590,  1997,  4793,  6650,  1012,   102,     0],\n",
      "        [  101,  2943,  5703,  5942,  1044, 22571, 14573,  7911,  7712,  1043,\n",
      "          7630, 28282,  2618, 11265, 10976,  6494,  3619, 25481,  1012,   102]]) tensor([[  101, 24216,  2015,  2090,  7435,  1998,  5022,  2064,  2599,  2000,\n",
      "          2512,  1011, 29235,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  4013, 15509, 18514,  3977,  1997,  4013,  6914, 27287,\n",
      "          2003, 12222,  3526,  1011,  8392,  2135,  1012,   102,     0],\n",
      "        [  101,  3949,  2007,  1037,  5250,  2315,  1042,  2078,  9239,  2015,\n",
      "         19723, 24454,  8082,  7590,  1997,  4793,  6650,  1012,   102],\n",
      "        [  101,  2943,  5703,  5942,  1044, 22571, 14573,  7911,  7712,  1043,\n",
      "          7630, 28282,  2618, 11265, 10976,  6494,  3619, 25481,  1012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101, 19802,  6190,  3141, 13356,  2038,  2815,  6540,  2090,  2268,\n",
      "          1011,  2297,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2822,  3633,  2007, 23746, 24004,  9096, 12333,  3012,  1999,\n",
      "          1996, 11047,  2232, 19699,  4962,  2024,  2625,  8211,  2000, 13692,\n",
      "          3303,  2011,  2659,  3798,  1997,  1042, 19425, 13822,  1012,   102],\n",
      "        [  101,  2146,  4677, 26572,  4609, 16846,  4648,  3064, 19101, 12737,\n",
      "         12448,  3370, 13416,  1059, 21030,  6774,  1998, 26180,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10507,  2140, 16147,  2003,  1037, 27854,  2005, 10507,  2099,\n",
      "          2581,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]) tensor([[  101, 19802,  6190,  3141, 13356,  2038,  2815,  6540,  2090,  2268,\n",
      "          1011,  2297,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2822,  3633,  2007, 23746, 24004,  9096, 12333,  3012,  1999,\n",
      "          1996, 11047,  2232, 19699,  4962,  2024,  2625,  8211,  2000, 13692,\n",
      "          3303,  2011,  2659,  3798,  1997,  1042, 19425, 13822,  1012],\n",
      "        [  101,  2146,  4677, 26572,  4609, 16846,  4648,  3064, 19101, 12737,\n",
      "         12448,  3370, 13416,  1059, 21030,  6774,  1998, 26180,  1012,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101, 10507,  2140, 16147,  2003,  1037, 27854,  2005, 10507,  2099,\n",
      "          2581,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[  101, 23025,  2389,  2417, 11636, 16285, 15176,  2552,  2378, 10949,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  3670,  1997,  2006, 25778, 21252,  7865, 28873,  2015,  2004,\n",
      "         25117,  2015,  3084,  2128,  2721, 29251,  2062,  3497,  1012,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101, 10210, 11663, 15422,  4360,  2377,  1037,  2350,  2535,  1999,\n",
      "          9706,  7361, 25950,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  2019, 25525,  1011,  2066,  6887, 16515, 13874,  1999,  2829,\n",
      "         27133, 20688,  8153, 26632, 21890,  8449,  2003,  2855, 10572,  2011,\n",
      "          3147,  7524,  1012,   102]]) tensor([[  101, 23025,  2389,  2417, 11636, 16285, 15176,  2552,  2378, 10949,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  3670,  1997,  2006, 25778, 21252,  7865, 28873,  2015,  2004,\n",
      "         25117,  2015,  3084,  2128,  2721, 29251,  2062,  3497,  1012,   102,\n",
      "             0,     0,     0],\n",
      "        [  101, 10210, 11663, 15422,  4360,  2377,  1037,  2350,  2535,  1999,\n",
      "          9706,  7361, 25950,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [  101,  2019, 25525,  1011,  2066,  6887, 16515, 13874,  1999,  2829,\n",
      "         27133, 20688,  8153, 26632, 21890,  8449,  2003,  2855, 10572,  2011,\n",
      "          3147,  7524,  1012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3445, 18433,  1997, 22330, 14399,  8523,  7712, 24972,  7275,\n",
      "          2013,  2058, 10288, 20110,  5668,  2003,  5393,  2011,  6428,  7516,\n",
      "          2005, 18168, 14376,  1999, 14134, 24869,  1011,  3931, 21500,  2015,\n",
      "          1012,   102],\n",
      "        [  101, 29486,  2953,  4442,  2024,  2028,  3114,  2005, 12958, 10960,\n",
      "          2000,  5939,  7352,  3170, 21903, 24054,  1006,  1056,  3211,  1007,\n",
      "          7242,  1999,  4456,  5022,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3465, 12353,  9312,  2015,  2241,  2006, 13675,  6593,  2951,\n",
      "         14125,  8339,  7597,  2005,  5022,  1999,  5025,  6612,  3218,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 22466,  4017,  7277,  5970,  5260,  2000,  3893, 13105,  1999,\n",
      "          5177,  2740,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]) tensor([[  101,  3445, 18433,  1997, 22330, 14399,  8523,  7712, 24972,  7275,\n",
      "          2013,  2058, 10288, 20110,  5668,  2003,  5393,  2011,  6428,  7516,\n",
      "          2005, 18168, 14376,  1999, 14134, 24869,  1011,  3931, 21500,  2015,\n",
      "          1012],\n",
      "        [  101, 29486,  2953,  4442,  2024,  2028,  3114,  2005, 12958, 10960,\n",
      "          2000,  5939,  7352,  3170, 21903, 24054,  1006,  1056,  3211,  1007,\n",
      "          7242,  1999,  4456,  5022,  1012,   102,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  3465, 12353,  9312,  2015,  2241,  2006, 13675,  6593,  2951,\n",
      "         14125,  8339,  7597,  2005,  5022,  1999,  5025,  6612,  3218,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101, 22466,  4017,  7277,  5970,  5260,  2000,  3893, 13105,  1999,\n",
      "          5177,  2740,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  3078, 28711,  4456, 11326,  2007,  6522,  2615, 10788,  2038,\n",
      "          2896, 20134, 14639,  2084,  7511, 22330, 23479,  2000, 11487, 28711,\n",
      "         26721, 13699,  8939, 24587,  9253, 24759, 15396,  3694,  1016,  1012,\n",
      "           102],\n",
      "        [  101, 20199,  1011,  3772,  1048, 12273, 12789,  2015,  2491,  1996,\n",
      "          3670,  1997,  9165,  2008,  2024, 10959,  1999,  1996,  9884,  1997,\n",
      "          2037, 14193,  4573,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  5915,  6887,  2891,  8458,  4140,  5521, 22747,  2121,  6165,\n",
      "          2024, 23900,  2007,  2010,  3775, 10672, 21903, 21618,  3563,  3012,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  101,  5622,  3401,  2012,  6528, 16453,  9033,  2615, 28896, 19653,\n",
      "          1037,  6428, 28873,  1011,  3563,  1056,  3526,  3433,  1999,  1048,\n",
      "         24335,  8458, 13045,  4442,  1012,   102,     0,     0,     0,     0,\n",
      "             0]]) tensor([[  101,  3078, 28711,  4456, 11326,  2007,  6522,  2615, 10788,  2038,\n",
      "          2896, 20134, 14639,  2084,  7511, 22330, 23479,  2000, 11487, 28711,\n",
      "         26721, 13699,  8939, 24587,  9253, 24759, 15396,  3694,  1016,  1012],\n",
      "        [  101, 20199,  1011,  3772,  1048, 12273, 12789,  2015,  2491,  1996,\n",
      "          3670,  1997,  9165,  2008,  2024, 10959,  1999,  1996,  9884,  1997,\n",
      "          2037, 14193,  4573,  1012,   102,     0,     0,     0,     0,     0],\n",
      "        [  101,  5915,  6887,  2891,  8458,  4140,  5521, 22747,  2121,  6165,\n",
      "          2024, 23900,  2007,  2010,  3775, 10672, 21903, 21618,  3563,  3012,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5622,  3401,  2012,  6528, 16453,  9033,  2615, 28896, 19653,\n",
      "          1037,  6428, 28873,  1011,  3563,  1056,  3526,  3433,  1999,  1048,\n",
      "         24335,  8458, 13045,  4442,  1012,   102,     0,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1055,  2078,  2003,  2556,  2006,  9677,  5887,  2015,  2076,\n",
      "         21733,  1999, 24269,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2088,  2740,  3029,  1005,  1055,  1006,  2040,  1007,\n",
      "          2951,  3074,  2832,  2003, 25352, 14047,  2011, 16655, 26426,  4989,\n",
      "          1997,  3469,  8293,  2015,  1012,   102],\n",
      "        [  101,  1047, 10270,  2549,  2003,  2590,  2005,  5372,  2026, 18349,\n",
      "          3593,  3526, 20582,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1050, 22022,  2620,  2072, 14494,  3426,  5012,  2000, 11265,\n",
      "         24093, 19265,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]) tensor([[  101,  1055,  2078,  2003,  2556,  2006,  9677,  5887,  2015,  2076,\n",
      "         21733,  1999, 24269,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2088,  2740,  3029,  1005,  1055,  1006,  2040,  1007,\n",
      "          2951,  3074,  2832,  2003, 25352, 14047,  2011, 16655, 26426,  4989,\n",
      "          1997,  3469,  8293,  2015,  1012],\n",
      "        [  101,  1047, 10270,  2549,  2003,  2590,  2005,  5372,  2026, 18349,\n",
      "          3593,  3526, 20582,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  1050, 22022,  2620,  2072, 14494,  3426,  5012,  2000, 11265,\n",
      "         24093, 19265,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   5%|▌         | 11/202 [00:02<00:50,  3.75it/s]\n",
      "Epoch:   0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2659,  3670,  1997, 14719,  2581,  2050,  2515,  2025, 16360,\n",
      "          8303,  4539,  9165,  2030,  4654,  8743,  1037,  6897,  3853,  1999,\n",
      "          3231,  2483,  1012,   102,     0,     0,     0,     0],\n",
      "        [  101,  4761,  7977,  4968,  4031,  1006, 14230,  1007,  2003, 13567,\n",
      "          3141,  2000, 26957,  5657,  7865,  1006,  7939,  2615,  1011,  1015,\n",
      "          1007, 19241,  1999,  2250,  4026, 24636,  1012,   102],\n",
      "        [  101,  2045,  2003,  2053,  2124,  8290,  2090,  7156,  5387, 13323,\n",
      "          2509,  1013,  1018,  1998,  2350, 10381, 21716, 20363,  2128,  5302,\n",
      "          9247,  2075,  5876,  1012,   102,     0,     0,     0],\n",
      "        [  101,  8319,  3526,  1011,  2489, 23079,  6064,  3798,  2024,  3378,\n",
      "          2007, 13356,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]) tensor([[  101,  2659,  3670,  1997, 14719,  2581,  2050,  2515,  2025, 16360,\n",
      "          8303,  4539,  9165,  2030,  4654,  8743,  1037,  6897,  3853,  1999,\n",
      "          3231,  2483,  1012,   102,     0,     0,     0],\n",
      "        [  101,  4761,  7977,  4968,  4031,  1006, 14230,  1007,  2003, 13567,\n",
      "          3141,  2000, 26957,  5657,  7865,  1006,  7939,  2615,  1011,  1015,\n",
      "          1007, 19241,  1999,  2250,  4026, 24636,  1012],\n",
      "        [  101,  2045,  2003,  2053,  2124,  8290,  2090,  7156,  5387, 13323,\n",
      "          2509,  1013,  1018,  1998,  2350, 10381, 21716, 20363,  2128,  5302,\n",
      "          9247,  2075,  5876,  1012,   102,     0,     0],\n",
      "        [  101,  8319,  3526,  1011,  2489, 23079,  6064,  3798,  2024,  3378,\n",
      "          2007, 13356,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# evaluator=dev_evaluator,\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# evaluation_steps=evaluation_steps,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# output_path=model_save_path,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True, if your GPU supports FP16 cores\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/sentence_transformers/SentenceTransformer.py:965\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    963\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    964\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(loss_model\u001b[38;5;241m.\u001b[39mparameters(), max_grad_norm)\n\u001b[0;32m--> 965\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    968\u001b[0m skip_scheduler \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mget_scale() \u001b[38;5;241m!=\u001b[39m scale_before_step\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:378\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/adamw.py:187\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    176\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    177\u001b[0m         group,\n\u001b[1;32m    178\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m         state_steps,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/adamw.py:339\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 339\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/torch/optim/adamw.py:470\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    468\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    472\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    # evaluator=dev_evaluator,\n",
    "    epochs=1,\n",
    "    # evaluation_steps=evaluation_steps,\n",
    "    # output_path=model_save_path,\n",
    "    weight_decay=0,\n",
    "    warmup_steps=100,\n",
    "    optimizer_params={\"lr\": 3e-5},\n",
    "    use_amp=True,  # Set to True, if your GPU supports FP16 cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[MASK]dasdf ads[MASK] sda [MASK]ds [MASK]asd gasdg aasdfa[MASK]f /dsaf sadfsd,dasfa[MASK]f. [MASK]ds[MASK].fads,fadsfa',\n",
       " '[MASK]dasdf [MASK][MASK] sda fads [MASK]asd gas[MASK]g [MASK]sd[MASK][MASK][MASK] [MASK][MASK]af [MASK][MASK][MASK][MASK]dasfadsf[MASK] [MASK][MASK][MASK].fads[MASK]fads[MASK]',\n",
       " \"asdasdf adsf sda fads 'asd gasdg aasdfasdf /dsaf sadfsd,dasfadsf. fadsf.fads,fadsfa\"]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(MaskedAutoEncoderDataset([\"asdasdf adsf sda fads 'asd gasdg aasdfasdf /dsaf sadfsd,dasfadsf. fadsf.fads,fadsfa\"],tokenizer))).texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asdasdf adsf sda fads ' asd gasdg aasdfasdf / dsaf sadfsd, dasfadsf. fadsf. fads, fadsfa\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"asdasdf adsf sda fads 'asd gasdg aasdfasdf /dsaf sadfsd,dasfadsf. fadsf.fads,fadsfa\"\n",
    "tokenizer.decode(tokenizer.encode_plus(sentence,return_attention_mask=False,return_token_type_ids=False,add_special_tokens=False)['input_ids'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as [MASK] df'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode('as [MASK]df',add_special_tokens=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/cgrdj/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/share/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m masked_sentences\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[0;32m----> 4\u001b[0m     words\u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Apply the masking logic to each word and rejoin the sentence\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     splitted_tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(words,return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,return_token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/Documents/code/repos/sentence-transformers/.conda/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/cgrdj/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/share/nltk_data'\n    - '/home/cgrdj/Documents/code/repos/sentence-transformers/.conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences=[\"asdasdf adsf sda fads 'asd gasdg aasdfasdf /dsaf sadfsd,dasfadsf. fadsf.fads,fadsfa\"]*10000\n",
    "masked_sentences=[]\n",
    "for sentence in sentences:\n",
    "    words= word_tokenize(sentence)\n",
    "    # Apply the masking logic to each word and rejoin the sentence\n",
    "    splitted_tokens = tokenizer.batch_encode_plus(words,return_attention_mask=False,return_token_type_ids=False,add_special_tokens=False)['input_ids']\n",
    "    masked_sentence=' '.join([tokenizer.decode([ mask_id if np.random.rand() < mask_probability else tok_id for tok_id in word]).replace(\" \",'') for word in splitted_tokens])\n",
    "    masked_sentences.append(masked_sentence)\n",
    "\n",
    "\n",
    "\n",
    "# masked_sentence = ' '.join([mask_token if np.random.rand() < mask_probability else word for word in words])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6904, 5104, 2546, 1012, 6904, 5104]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_spaces_table=str.maketrans('', '', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.5 µs ± 2.3 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "tokenizer.decode([ mask_id if np.random.rand() < mask_probability else tok_id for tok_id in splitted_tokens[12]]).replace(\" \",'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.8 µs ± 4.79 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100000\n",
    "tokenizer.decode([ mask_id if np.random.rand() < mask_probability else tok_id for tok_id in splitted_tokens[12]]).translate(remove_spaces_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1042, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'tokens': 'int' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/sentence-transformers/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:612\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.convert_tokens_to_string\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_tokens_to_string\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'tokens': 'int' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer(sentence)['input_ids'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asdas [MASK] adsf sda fads ' asd gas [MASK]g aasdfasdf / dsaf sad [MASK]d, [MASK]fadsf. fadsf. fa [MASK], fadsfa\""
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_probability=0.15\n",
    "mask_token = tokenizer.mask_token  # Get the mask token\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "# Decide randomly which tokens to mask\n",
    "masked_indices = np.random.rand(len(tokens)) < mask_probability\n",
    "# Replace selected tokens with the mask token\n",
    "masked_tokens = [mask_token if mask else token for token, mask in zip(tokens, masked_indices)]\n",
    "# Convert the list of tokens back to a string\n",
    "masked_sentence = tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "# Add the masked sentence to the list\n",
    "# masked_sentences.append(masked_sentence)\n",
    "masked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"as [MASK]df adsf sd [MASK] fads ' asd gas [MASK]g aa [MASK]fasdf [MASK] [MASK] [MASK] sadfsd, dasfadsf. [MASK] [MASK] [MASK]. fads [MASK] fa [MASK]fa\""
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdasdf',\n",
       " 'adsf',\n",
       " 'sda',\n",
       " 'fads',\n",
       " \"'asd\",\n",
       " 'gasdg',\n",
       " 'aasdfasdf',\n",
       " '/dsaf',\n",
       " 'sadfsd',\n",
       " ',',\n",
       " 'dasfadsf',\n",
       " '.',\n",
       " 'fadsf.fads',\n",
       " ',',\n",
       " 'fadsfa']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_tokenize(sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded here: /Users/cgrdj/Documents/Code/sentence-transformers/datasets/scifact\n"
     ]
    }
   ],
   "source": [
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "print(\"Dataset downloaded here: {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:49:24 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 11485.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:49:24 - Loaded 5183 TRAIN Documents.\n",
      "2024-03-16 00:49:24 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2024-03-16 00:49:24 - Loading Queries...\n",
      "2024-03-16 00:49:24 - Loaded 809 TRAIN Queries.\n",
      "2024-03-16 00:49:24 - Query Example: 0-dimensional biomaterials lack inductive properties.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"train\") # or split = \"train\" or \"dev\"\n",
    "unsupervised_train_data =  list(queries.values())#+[data['title']+' \\n '+data['text'] for data in list(corpus.values())]\n",
    "random.Random(0).shuffle(unsupervised_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:49:25 - Loading Corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5183 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [00:00<00:00, 16216.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 00:49:26 - Loaded 5183 TEST Documents.\n",
      "2024-03-16 00:49:26 - Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}\n",
      "2024-03-16 00:49:26 - Loading Queries...\n",
      "2024-03-16 00:49:26 - Loaded 300 TEST Queries.\n",
      "2024-03-16 00:49:26 - Query Example: 0-dimensional biomaterials show inductive properties.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"datasets/scifact\"\n",
    "test_corpus, test_queries, test_qrels = GenericDataLoader(data_path).load(split=\"test\") # or split = \"train\" or \"dev\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
